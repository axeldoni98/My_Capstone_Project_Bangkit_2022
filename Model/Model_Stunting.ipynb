{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBmdqywRham4",
        "outputId": "871dce73-a73e-4648-8193-c1cb218e54e8"
      },
      "id": "rBmdqywRham4",
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "f4c8a51e",
      "metadata": {
        "id": "f4c8a51e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras import backend as K\n",
        "import tensorflow_addons as tfa\n",
        "from google.colab import files\n",
        "import pathlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "QT98gPQgcFmo"
      },
      "id": "QT98gPQgcFmo"
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "8c51cbd7",
      "metadata": {
        "id": "8c51cbd7"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/sample_data/Stunting_Train.csv')\n",
        "\n",
        "x_train = df_train.values\n",
        "x_train = np.delete(x_train,6, axis=1)\n",
        "y_train = df_train['OUTCOME'].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4-GmcxrZZ5-3",
        "outputId": "724aa530-e8bc-4349-89ef-d54a7a87e55a"
      },
      "id": "4-GmcxrZZ5-3",
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     AGE (MONTH)  HEIGHT (CM)  WEIGHT (KG)  HEAD CIRCUM (CM)  CHEST SIZE (CM)  \\\n",
              "0             33         88.0         12.0                49               55   \n",
              "1              3         55.0          8.0                42               44   \n",
              "2             35         87.0         12.0                51               47   \n",
              "3             25         83.0         10.0                49               48   \n",
              "4             24         83.0         11.0                46               47   \n",
              "..           ...          ...          ...               ...              ...   \n",
              "145           12         68.0         14.0                45               46   \n",
              "146           26         84.5         10.0                50               50   \n",
              "147            7         65.0          9.0                49               49   \n",
              "148           48        110.0         12.0                46               49   \n",
              "149           38         90.0         11.0                48               49   \n",
              "\n",
              "     BELLY CIRCUM (CM)  OUTCOME  \n",
              "0                   47        0  \n",
              "1                   47        0  \n",
              "2                   47        0  \n",
              "3                   48        0  \n",
              "4                   47        0  \n",
              "..                 ...      ...  \n",
              "145                 45        1  \n",
              "146                 50        0  \n",
              "147                 49        0  \n",
              "148                 46        1  \n",
              "149                 48        1  \n",
              "\n",
              "[150 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07030984-54ce-48dd-bad3-2eaedf69630a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE (MONTH)</th>\n",
              "      <th>HEIGHT (CM)</th>\n",
              "      <th>WEIGHT (KG)</th>\n",
              "      <th>HEAD CIRCUM (CM)</th>\n",
              "      <th>CHEST SIZE (CM)</th>\n",
              "      <th>BELLY CIRCUM (CM)</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33</td>\n",
              "      <td>88.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>49</td>\n",
              "      <td>55</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>55.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>42</td>\n",
              "      <td>44</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35</td>\n",
              "      <td>87.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>51</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>83.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>83.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>46</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>12</td>\n",
              "      <td>68.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>26</td>\n",
              "      <td>84.5</td>\n",
              "      <td>10.0</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>7</td>\n",
              "      <td>65.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>49</td>\n",
              "      <td>49</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>48</td>\n",
              "      <td>110.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>46</td>\n",
              "      <td>49</td>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>38</td>\n",
              "      <td>90.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07030984-54ce-48dd-bad3-2eaedf69630a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07030984-54ce-48dd-bad3-2eaedf69630a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07030984-54ce-48dd-bad3-2eaedf69630a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJEC-wskZc0M",
        "outputId": "fb19aa93-35f1-4191-c5c2-c9fd05eac5b7"
      },
      "id": "SJEC-wskZc0M",
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['AGE (MONTH)', 'HEIGHT (CM)', 'WEIGHT (KG)', 'HEAD CIRCUM (CM)',\n",
              "       'CHEST SIZE (CM)', 'BELLY CIRCUM (CM)', 'OUTCOME'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL1hrA-sZxpQ",
        "outputId": "34e93802-744e-4319-85eb-7922d761a059"
      },
      "id": "qL1hrA-sZxpQ",
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "uNb3ygPiaZZ4",
        "outputId": "b9c1c929-c181-489d-e8df-045e6e427c76"
      },
      "id": "uNb3ygPiaZZ4",
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   count       mean        std   min    25%   50%     75%  \\\n",
              "AGE (MONTH)        150.0  30.280000  16.974169   2.0  17.00  32.5  41.000   \n",
              "HEIGHT (CM)        150.0  83.903333  13.977774  50.0  75.25  86.0  92.750   \n",
              "WEIGHT (KG)        150.0  12.014000   5.297081   4.0   9.50  11.0  13.775   \n",
              "HEAD CIRCUM (CM)   150.0  47.793333   3.760081  35.0  46.00  49.0  50.000   \n",
              "CHEST SIZE (CM)    150.0  48.073333   4.976585  30.0  46.00  48.0  50.000   \n",
              "BELLY CIRCUM (CM)  150.0  48.146667   4.972929  32.0  46.00  48.0  50.000   \n",
              "OUTCOME            150.0   0.386667   0.488618   0.0   0.00   0.0   1.000   \n",
              "\n",
              "                     max  \n",
              "AGE (MONTH)         60.0  \n",
              "HEIGHT (CM)        111.0  \n",
              "WEIGHT (KG)         61.0  \n",
              "HEAD CIRCUM (CM)    59.0  \n",
              "CHEST SIZE (CM)     60.0  \n",
              "BELLY CIRCUM (CM)   61.0  \n",
              "OUTCOME              1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d76c6b2-6734-4496-98bc-2d6f7d8d8394\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AGE (MONTH)</th>\n",
              "      <td>150.0</td>\n",
              "      <td>30.280000</td>\n",
              "      <td>16.974169</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.00</td>\n",
              "      <td>32.5</td>\n",
              "      <td>41.000</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HEIGHT (CM)</th>\n",
              "      <td>150.0</td>\n",
              "      <td>83.903333</td>\n",
              "      <td>13.977774</td>\n",
              "      <td>50.0</td>\n",
              "      <td>75.25</td>\n",
              "      <td>86.0</td>\n",
              "      <td>92.750</td>\n",
              "      <td>111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WEIGHT (KG)</th>\n",
              "      <td>150.0</td>\n",
              "      <td>12.014000</td>\n",
              "      <td>5.297081</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.50</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.775</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HEAD CIRCUM (CM)</th>\n",
              "      <td>150.0</td>\n",
              "      <td>47.793333</td>\n",
              "      <td>3.760081</td>\n",
              "      <td>35.0</td>\n",
              "      <td>46.00</td>\n",
              "      <td>49.0</td>\n",
              "      <td>50.000</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHEST SIZE (CM)</th>\n",
              "      <td>150.0</td>\n",
              "      <td>48.073333</td>\n",
              "      <td>4.976585</td>\n",
              "      <td>30.0</td>\n",
              "      <td>46.00</td>\n",
              "      <td>48.0</td>\n",
              "      <td>50.000</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BELLY CIRCUM (CM)</th>\n",
              "      <td>150.0</td>\n",
              "      <td>48.146667</td>\n",
              "      <td>4.972929</td>\n",
              "      <td>32.0</td>\n",
              "      <td>46.00</td>\n",
              "      <td>48.0</td>\n",
              "      <td>50.000</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OUTCOME</th>\n",
              "      <td>150.0</td>\n",
              "      <td>0.386667</td>\n",
              "      <td>0.488618</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d76c6b2-6734-4496-98bc-2d6f7d8d8394')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d76c6b2-6734-4496-98bc-2d6f7d8d8394 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d76c6b2-6734-4496-98bc-2d6f7d8d8394');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df_train['OUTCOME'])\n",
        "plt.title(\"Outcome dari Stunting Train\")\n",
        "plt.ioff()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "IuCgUf10ZJWL",
        "outputId": "7df89979-ba60-4686-f8e2-e4380a44138a"
      },
      "id": "IuCgUf10ZJWL",
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "5a3b6e7d",
      "metadata": {
        "id": "5a3b6e7d"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('/content/sample_data/Stunting_Test.csv')\n",
        "\n",
        "x_test = df_test.values\n",
        "x_test = np.delete(x_test,6, axis=1)\n",
        "y_test = df_test['OUTCOME'].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "MlPbYQ-jbqID",
        "outputId": "f0004be3-efee-425a-bfc7-f4544cb276e7"
      },
      "id": "MlPbYQ-jbqID",
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     AGE (MONTH)  HEIGHT (CM)  WEIGHT (KG)  HEAD CIRCUM (CM)  CHEST SIZE (CM)  \\\n",
              "0             33         88.0         12.0                49               55   \n",
              "1              3         55.0          8.0                42               44   \n",
              "2             35         87.0         12.0                51               47   \n",
              "3             25         83.0         10.0                49               48   \n",
              "4             24         83.0         11.0                46               47   \n",
              "..           ...          ...          ...               ...              ...   \n",
              "113            6         65.0          7.2                42               48   \n",
              "114           36         91.0         11.5                48               47   \n",
              "115           20         87.0         10.0                43               44   \n",
              "116           41         89.5         11.0                50               52   \n",
              "117           38         90.0         11.0                48               49   \n",
              "\n",
              "     BELLY CIRCUM (CM)  OUTCOME  \n",
              "0                   47        0  \n",
              "1                   47        0  \n",
              "2                   47        0  \n",
              "3                   48        0  \n",
              "4                   47        0  \n",
              "..                 ...      ...  \n",
              "113                 44        0  \n",
              "114                 44        0  \n",
              "115                 44        0  \n",
              "116                 53        1  \n",
              "117                 48        1  \n",
              "\n",
              "[118 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07dc633d-d1c7-4524-83d1-a1cc4060d435\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE (MONTH)</th>\n",
              "      <th>HEIGHT (CM)</th>\n",
              "      <th>WEIGHT (KG)</th>\n",
              "      <th>HEAD CIRCUM (CM)</th>\n",
              "      <th>CHEST SIZE (CM)</th>\n",
              "      <th>BELLY CIRCUM (CM)</th>\n",
              "      <th>OUTCOME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33</td>\n",
              "      <td>88.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>49</td>\n",
              "      <td>55</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>55.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>42</td>\n",
              "      <td>44</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35</td>\n",
              "      <td>87.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>51</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>83.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>83.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>46</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>6</td>\n",
              "      <td>65.0</td>\n",
              "      <td>7.2</td>\n",
              "      <td>42</td>\n",
              "      <td>48</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>36</td>\n",
              "      <td>91.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>48</td>\n",
              "      <td>47</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>20</td>\n",
              "      <td>87.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>41</td>\n",
              "      <td>89.5</td>\n",
              "      <td>11.0</td>\n",
              "      <td>50</td>\n",
              "      <td>52</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>38</td>\n",
              "      <td>90.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>118 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07dc633d-d1c7-4524-83d1-a1cc4060d435')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07dc633d-d1c7-4524-83d1-a1cc4060d435 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07dc633d-d1c7-4524-83d1-a1cc4060d435');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENtCdeaHbcuv",
        "outputId": "30d33c08-627a-4d55-e486-f65dc2d53ae8"
      },
      "id": "ENtCdeaHbcuv",
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['AGE (MONTH)', 'HEIGHT (CM)', 'WEIGHT (KG)', 'HEAD CIRCUM (CM)',\n",
              "       'CHEST SIZE (CM)', 'BELLY CIRCUM (CM)', 'OUTCOME'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo2GVIw7bfp_",
        "outputId": "edecd4cc-f911-4480-fe7e-31183d27c770"
      },
      "id": "bo2GVIw7bfp_",
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "0iQzxjdJbuCs",
        "outputId": "4d958ce1-3271-4865-f293-56415d50fa78"
      },
      "id": "0iQzxjdJbuCs",
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   count       mean        std   min     25%   50%   75%  \\\n",
              "AGE (MONTH)        118.0  30.822034  17.533670   2.0  17.000  33.5  41.0   \n",
              "HEIGHT (CM)        118.0  83.449153  13.783024  50.0  76.000  86.5  92.0   \n",
              "WEIGHT (KG)        118.0  11.645763   5.573957   4.0   9.025  11.0  13.2   \n",
              "HEAD CIRCUM (CM)   118.0  47.881356   3.791961  35.0  46.000  49.0  50.0   \n",
              "CHEST SIZE (CM)    118.0  48.161017   4.639058  30.0  46.000  48.0  50.0   \n",
              "BELLY CIRCUM (CM)  118.0  48.194915   4.782908  32.0  46.000  48.0  50.0   \n",
              "OUTCOME            118.0   0.296610   0.458711   0.0   0.000   0.0   1.0   \n",
              "\n",
              "                     max  \n",
              "AGE (MONTH)         60.0  \n",
              "HEIGHT (CM)        111.0  \n",
              "WEIGHT (KG)         61.0  \n",
              "HEAD CIRCUM (CM)    59.0  \n",
              "CHEST SIZE (CM)     59.0  \n",
              "BELLY CIRCUM (CM)   60.0  \n",
              "OUTCOME              1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9fdcea1-c72e-430f-bd44-8638e40eaf9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AGE (MONTH)</th>\n",
              "      <td>118.0</td>\n",
              "      <td>30.822034</td>\n",
              "      <td>17.533670</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.000</td>\n",
              "      <td>33.5</td>\n",
              "      <td>41.0</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HEIGHT (CM)</th>\n",
              "      <td>118.0</td>\n",
              "      <td>83.449153</td>\n",
              "      <td>13.783024</td>\n",
              "      <td>50.0</td>\n",
              "      <td>76.000</td>\n",
              "      <td>86.5</td>\n",
              "      <td>92.0</td>\n",
              "      <td>111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WEIGHT (KG)</th>\n",
              "      <td>118.0</td>\n",
              "      <td>11.645763</td>\n",
              "      <td>5.573957</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.025</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.2</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HEAD CIRCUM (CM)</th>\n",
              "      <td>118.0</td>\n",
              "      <td>47.881356</td>\n",
              "      <td>3.791961</td>\n",
              "      <td>35.0</td>\n",
              "      <td>46.000</td>\n",
              "      <td>49.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHEST SIZE (CM)</th>\n",
              "      <td>118.0</td>\n",
              "      <td>48.161017</td>\n",
              "      <td>4.639058</td>\n",
              "      <td>30.0</td>\n",
              "      <td>46.000</td>\n",
              "      <td>48.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BELLY CIRCUM (CM)</th>\n",
              "      <td>118.0</td>\n",
              "      <td>48.194915</td>\n",
              "      <td>4.782908</td>\n",
              "      <td>32.0</td>\n",
              "      <td>46.000</td>\n",
              "      <td>48.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OUTCOME</th>\n",
              "      <td>118.0</td>\n",
              "      <td>0.296610</td>\n",
              "      <td>0.458711</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9fdcea1-c72e-430f-bd44-8638e40eaf9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9fdcea1-c72e-430f-bd44-8638e40eaf9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9fdcea1-c72e-430f-bd44-8638e40eaf9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df_test['OUTCOME'])\n",
        "plt.title('Outcome dari Stunting Test')\n",
        "plt.ioff()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "TdwB0kUxb9dK",
        "outputId": "6dcf0401-277d-43c0-c373-88ac7fca1b60"
      },
      "id": "TdwB0kUxb9dK",
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "id": "9f110301",
      "metadata": {
        "id": "9f110301"
      },
      "outputs": [],
      "source": [
        "x_train = MinMaxScaler().fit_transform(x_train)\n",
        "x_test  = MinMaxScaler().fit_transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 538,
      "id": "2c12442c",
      "metadata": {
        "id": "2c12442c"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(512, activation='relu', input_shape=[6,]),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 539,
      "id": "dae2bf1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dae2bf1b",
        "outputId": "8c474775-db86-4406-cd7a-4a69d207732f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_191 (Dense)           (None, 512)               3584      \n",
            "                                                                 \n",
            " dense_192 (Dense)           (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_193 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_194 (Dense)           (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,889\n",
            "Trainable params: 85,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "WyOgJMfxknsW"
      },
      "id": "WyOgJMfxknsW",
      "execution_count": 540,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 541,
      "id": "0ba13464",
      "metadata": {
        "id": "0ba13464",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "model.compile(loss ='binary_crossentropy', optimizer='adam', metrics= ['accuracy', f1_m,precision_m, recall_m])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 542,
      "id": "94fccb94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94fccb94",
        "outputId": "7f0b1502-53d3-4678-87b1-72e9cf216db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "11/11 - 2s - loss: 0.6933 - accuracy: 0.5238 - f1_m: 0.0711 - precision_m: 0.0481 - recall_m: 0.1818 - val_loss: 0.6677 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 2s/epoch - 151ms/step\n",
            "Epoch 2/400\n",
            "11/11 - 0s - loss: 0.6791 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6602 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 80ms/epoch - 7ms/step\n",
            "Epoch 3/400\n",
            "11/11 - 0s - loss: 0.6781 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6670 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 89ms/epoch - 8ms/step\n",
            "Epoch 4/400\n",
            "11/11 - 0s - loss: 0.6646 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6573 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 88ms/epoch - 8ms/step\n",
            "Epoch 5/400\n",
            "11/11 - 0s - loss: 0.6657 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6579 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 73ms/epoch - 7ms/step\n",
            "Epoch 6/400\n",
            "11/11 - 0s - loss: 0.6590 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6546 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 75ms/epoch - 7ms/step\n",
            "Epoch 7/400\n",
            "11/11 - 0s - loss: 0.6555 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6507 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 82ms/epoch - 7ms/step\n",
            "Epoch 8/400\n",
            "11/11 - 0s - loss: 0.6571 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6489 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 76ms/epoch - 7ms/step\n",
            "Epoch 9/400\n",
            "11/11 - 0s - loss: 0.6608 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6471 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 66ms/epoch - 6ms/step\n",
            "Epoch 10/400\n",
            "11/11 - 0s - loss: 0.6479 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6423 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 74ms/epoch - 7ms/step\n",
            "Epoch 11/400\n",
            "11/11 - 0s - loss: 0.6443 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6402 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 67ms/epoch - 6ms/step\n",
            "Epoch 12/400\n",
            "11/11 - 0s - loss: 0.6395 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6374 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 77ms/epoch - 7ms/step\n",
            "Epoch 13/400\n",
            "11/11 - 0s - loss: 0.6336 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6452 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 80ms/epoch - 7ms/step\n",
            "Epoch 14/400\n",
            "11/11 - 0s - loss: 0.6331 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6390 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 70ms/epoch - 6ms/step\n",
            "Epoch 15/400\n",
            "11/11 - 0s - loss: 0.6354 - accuracy: 0.6286 - f1_m: 0.0909 - precision_m: 0.1818 - recall_m: 0.0606 - val_loss: 0.6407 - val_accuracy: 0.6000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 63ms/epoch - 6ms/step\n",
            "Epoch 16/400\n",
            "11/11 - 0s - loss: 0.6260 - accuracy: 0.6190 - f1_m: 0.0364 - precision_m: 0.0909 - recall_m: 0.0227 - val_loss: 0.6379 - val_accuracy: 0.6222 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 84ms/epoch - 8ms/step\n",
            "Epoch 17/400\n",
            "11/11 - 0s - loss: 0.6150 - accuracy: 0.6095 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.6342 - val_accuracy: 0.6000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 80ms/epoch - 7ms/step\n",
            "Epoch 18/400\n",
            "11/11 - 0s - loss: 0.6070 - accuracy: 0.6476 - f1_m: 0.1636 - precision_m: 0.3636 - recall_m: 0.1091 - val_loss: 0.6323 - val_accuracy: 0.6444 - val_f1_m: 0.1371 - val_precision_m: 0.3000 - val_recall_m: 0.0900 - 81ms/epoch - 7ms/step\n",
            "Epoch 19/400\n",
            "11/11 - 0s - loss: 0.6012 - accuracy: 0.6476 - f1_m: 0.2394 - precision_m: 0.4545 - recall_m: 0.1727 - val_loss: 0.6349 - val_accuracy: 0.6222 - val_f1_m: 0.1238 - val_precision_m: 0.2000 - val_recall_m: 0.0900 - 70ms/epoch - 6ms/step\n",
            "Epoch 20/400\n",
            "11/11 - 0s - loss: 0.5872 - accuracy: 0.6381 - f1_m: 0.3424 - precision_m: 0.5303 - recall_m: 0.2652 - val_loss: 0.6339 - val_accuracy: 0.6222 - val_f1_m: 0.1571 - val_precision_m: 0.2000 - val_recall_m: 0.1300 - 81ms/epoch - 7ms/step\n",
            "Epoch 21/400\n",
            "11/11 - 0s - loss: 0.5819 - accuracy: 0.6286 - f1_m: 0.3684 - precision_m: 0.4848 - recall_m: 0.3636 - val_loss: 0.6384 - val_accuracy: 0.6222 - val_f1_m: 0.2000 - val_precision_m: 0.2333 - val_recall_m: 0.1800 - 77ms/epoch - 7ms/step\n",
            "Epoch 22/400\n",
            "11/11 - 0s - loss: 0.5770 - accuracy: 0.6667 - f1_m: 0.3749 - precision_m: 0.6061 - recall_m: 0.2955 - val_loss: 0.6373 - val_accuracy: 0.6000 - val_f1_m: 0.1571 - val_precision_m: 0.2000 - val_recall_m: 0.1300 - 70ms/epoch - 6ms/step\n",
            "Epoch 23/400\n",
            "11/11 - 0s - loss: 0.5766 - accuracy: 0.6857 - f1_m: 0.5118 - precision_m: 0.6818 - recall_m: 0.4528 - val_loss: 0.6357 - val_accuracy: 0.5556 - val_f1_m: 0.4000 - val_precision_m: 0.3762 - val_recall_m: 0.4333 - 78ms/epoch - 7ms/step\n",
            "Epoch 24/400\n",
            "11/11 - 0s - loss: 0.5627 - accuracy: 0.7333 - f1_m: 0.5147 - precision_m: 0.5727 - recall_m: 0.4879 - val_loss: 0.6580 - val_accuracy: 0.6000 - val_f1_m: 0.0800 - val_precision_m: 0.2000 - val_recall_m: 0.0500 - 102ms/epoch - 9ms/step\n",
            "Epoch 25/400\n",
            "11/11 - 0s - loss: 0.5894 - accuracy: 0.6667 - f1_m: 0.3369 - precision_m: 0.4439 - recall_m: 0.3074 - val_loss: 0.6125 - val_accuracy: 0.6444 - val_f1_m: 0.2905 - val_precision_m: 0.4167 - val_recall_m: 0.2367 - 129ms/epoch - 12ms/step\n",
            "Epoch 26/400\n",
            "11/11 - 0s - loss: 0.5735 - accuracy: 0.6857 - f1_m: 0.3297 - precision_m: 0.4970 - recall_m: 0.2788 - val_loss: 0.6214 - val_accuracy: 0.5556 - val_f1_m: 0.2905 - val_precision_m: 0.4167 - val_recall_m: 0.2367 - 153ms/epoch - 14ms/step\n",
            "Epoch 27/400\n",
            "11/11 - 0s - loss: 0.5789 - accuracy: 0.6762 - f1_m: 0.6114 - precision_m: 0.5714 - recall_m: 0.7621 - val_loss: 0.6184 - val_accuracy: 0.6667 - val_f1_m: 0.3171 - val_precision_m: 0.4267 - val_recall_m: 0.2767 - 216ms/epoch - 20ms/step\n",
            "Epoch 28/400\n",
            "11/11 - 0s - loss: 0.5470 - accuracy: 0.7048 - f1_m: 0.5165 - precision_m: 0.6742 - recall_m: 0.4515 - val_loss: 0.6212 - val_accuracy: 0.6444 - val_f1_m: 0.2905 - val_precision_m: 0.4167 - val_recall_m: 0.2367 - 112ms/epoch - 10ms/step\n",
            "Epoch 29/400\n",
            "11/11 - 0s - loss: 0.5441 - accuracy: 0.6667 - f1_m: 0.5275 - precision_m: 0.5780 - recall_m: 0.5985 - val_loss: 0.6177 - val_accuracy: 0.6667 - val_f1_m: 0.3333 - val_precision_m: 0.4500 - val_recall_m: 0.2867 - 163ms/epoch - 15ms/step\n",
            "Epoch 30/400\n",
            "11/11 - 0s - loss: 0.5375 - accuracy: 0.6857 - f1_m: 0.4714 - precision_m: 0.5394 - recall_m: 0.4470 - val_loss: 0.5996 - val_accuracy: 0.6667 - val_f1_m: 0.3800 - val_precision_m: 0.4200 - val_recall_m: 0.3533 - 153ms/epoch - 14ms/step\n",
            "Epoch 31/400\n",
            "11/11 - 0s - loss: 0.5465 - accuracy: 0.6952 - f1_m: 0.5071 - precision_m: 0.7636 - recall_m: 0.4697 - val_loss: 0.6073 - val_accuracy: 0.6667 - val_f1_m: 0.3333 - val_precision_m: 0.4500 - val_recall_m: 0.2867 - 117ms/epoch - 11ms/step\n",
            "Epoch 32/400\n",
            "11/11 - 0s - loss: 0.5403 - accuracy: 0.7048 - f1_m: 0.6139 - precision_m: 0.6364 - recall_m: 0.6667 - val_loss: 0.6165 - val_accuracy: 0.6000 - val_f1_m: 0.3400 - val_precision_m: 0.3600 - val_recall_m: 0.3267 - 142ms/epoch - 13ms/step\n",
            "Epoch 33/400\n",
            "11/11 - 0s - loss: 0.5154 - accuracy: 0.7429 - f1_m: 0.5232 - precision_m: 0.6455 - recall_m: 0.4894 - val_loss: 0.6090 - val_accuracy: 0.6667 - val_f1_m: 0.3333 - val_precision_m: 0.4500 - val_recall_m: 0.2867 - 148ms/epoch - 13ms/step\n",
            "Epoch 34/400\n",
            "11/11 - 0s - loss: 0.5213 - accuracy: 0.7238 - f1_m: 0.5747 - precision_m: 0.7667 - recall_m: 0.5132 - val_loss: 0.6039 - val_accuracy: 0.6667 - val_f1_m: 0.3505 - val_precision_m: 0.4167 - val_recall_m: 0.3033 - 162ms/epoch - 15ms/step\n",
            "Epoch 35/400\n",
            "11/11 - 0s - loss: 0.5169 - accuracy: 0.7238 - f1_m: 0.6265 - precision_m: 0.6056 - recall_m: 0.7667 - val_loss: 0.6075 - val_accuracy: 0.6889 - val_f1_m: 0.4667 - val_precision_m: 0.6500 - val_recall_m: 0.3867 - 135ms/epoch - 12ms/step\n",
            "Epoch 36/400\n",
            "11/11 - 0s - loss: 0.5698 - accuracy: 0.6857 - f1_m: 0.4472 - precision_m: 0.7273 - recall_m: 0.3978 - val_loss: 0.6174 - val_accuracy: 0.6222 - val_f1_m: 0.4305 - val_precision_m: 0.4300 - val_recall_m: 0.4433 - 109ms/epoch - 10ms/step\n",
            "Epoch 37/400\n",
            "11/11 - 0s - loss: 0.5251 - accuracy: 0.7333 - f1_m: 0.5842 - precision_m: 0.5879 - recall_m: 0.6613 - val_loss: 0.6002 - val_accuracy: 0.6444 - val_f1_m: 0.5267 - val_precision_m: 0.5700 - val_recall_m: 0.5200 - 157ms/epoch - 14ms/step\n",
            "Epoch 38/400\n",
            "11/11 - 0s - loss: 0.5028 - accuracy: 0.7143 - f1_m: 0.5072 - precision_m: 0.7121 - recall_m: 0.4470 - val_loss: 0.6084 - val_accuracy: 0.6667 - val_f1_m: 0.4000 - val_precision_m: 0.5500 - val_recall_m: 0.3367 - 217ms/epoch - 20ms/step\n",
            "Epoch 39/400\n",
            "11/11 - 0s - loss: 0.5022 - accuracy: 0.7333 - f1_m: 0.6501 - precision_m: 0.6641 - recall_m: 0.6992 - val_loss: 0.6119 - val_accuracy: 0.6667 - val_f1_m: 0.4000 - val_precision_m: 0.5500 - val_recall_m: 0.3367 - 155ms/epoch - 14ms/step\n",
            "Epoch 40/400\n",
            "11/11 - 0s - loss: 0.5043 - accuracy: 0.7238 - f1_m: 0.4721 - precision_m: 0.6818 - recall_m: 0.3803 - val_loss: 0.6044 - val_accuracy: 0.6889 - val_f1_m: 0.4800 - val_precision_m: 0.6500 - val_recall_m: 0.4033 - 153ms/epoch - 14ms/step\n",
            "Epoch 41/400\n",
            "11/11 - 0s - loss: 0.5108 - accuracy: 0.7524 - f1_m: 0.6279 - precision_m: 0.6561 - recall_m: 0.6682 - val_loss: 0.6090 - val_accuracy: 0.6889 - val_f1_m: 0.4000 - val_precision_m: 0.5500 - val_recall_m: 0.3367 - 177ms/epoch - 16ms/step\n",
            "Epoch 42/400\n",
            "11/11 - 0s - loss: 0.5115 - accuracy: 0.7429 - f1_m: 0.6149 - precision_m: 0.7045 - recall_m: 0.6348 - val_loss: 0.6045 - val_accuracy: 0.6889 - val_f1_m: 0.5133 - val_precision_m: 0.6500 - val_recall_m: 0.4533 - 187ms/epoch - 17ms/step\n",
            "Epoch 43/400\n",
            "11/11 - 0s - loss: 0.4829 - accuracy: 0.7429 - f1_m: 0.5768 - precision_m: 0.6561 - recall_m: 0.5364 - val_loss: 0.5998 - val_accuracy: 0.6667 - val_f1_m: 0.5171 - val_precision_m: 0.5867 - val_recall_m: 0.4700 - 137ms/epoch - 12ms/step\n",
            "Epoch 44/400\n",
            "11/11 - 0s - loss: 0.4705 - accuracy: 0.7619 - f1_m: 0.6058 - precision_m: 0.6515 - recall_m: 0.5894 - val_loss: 0.6169 - val_accuracy: 0.7111 - val_f1_m: 0.5743 - val_precision_m: 0.6533 - val_recall_m: 0.5200 - 138ms/epoch - 13ms/step\n",
            "Epoch 45/400\n",
            "11/11 - 0s - loss: 0.4671 - accuracy: 0.7429 - f1_m: 0.5657 - precision_m: 0.5545 - recall_m: 0.6258 - val_loss: 0.5963 - val_accuracy: 0.7111 - val_f1_m: 0.5000 - val_precision_m: 0.7500 - val_recall_m: 0.4033 - 190ms/epoch - 17ms/step\n",
            "Epoch 46/400\n",
            "11/11 - 0s - loss: 0.4695 - accuracy: 0.7429 - f1_m: 0.4683 - precision_m: 0.6333 - recall_m: 0.4102 - val_loss: 0.6009 - val_accuracy: 0.7111 - val_f1_m: 0.5333 - val_precision_m: 0.6833 - val_recall_m: 0.4700 - 135ms/epoch - 12ms/step\n",
            "Epoch 47/400\n",
            "11/11 - 0s - loss: 0.4767 - accuracy: 0.7905 - f1_m: 0.6377 - precision_m: 0.7485 - recall_m: 0.6346 - val_loss: 0.6207 - val_accuracy: 0.7778 - val_f1_m: 0.6911 - val_precision_m: 0.7133 - val_recall_m: 0.6867 - 192ms/epoch - 17ms/step\n",
            "Epoch 48/400\n",
            "11/11 - 0s - loss: 0.4657 - accuracy: 0.7333 - f1_m: 0.6166 - precision_m: 0.7364 - recall_m: 0.5944 - val_loss: 0.5981 - val_accuracy: 0.6889 - val_f1_m: 0.4800 - val_precision_m: 0.6500 - val_recall_m: 0.4033 - 172ms/epoch - 16ms/step\n",
            "Epoch 49/400\n",
            "11/11 - 0s - loss: 0.4568 - accuracy: 0.7619 - f1_m: 0.5497 - precision_m: 0.6970 - recall_m: 0.5004 - val_loss: 0.6120 - val_accuracy: 0.6889 - val_f1_m: 0.4800 - val_precision_m: 0.6500 - val_recall_m: 0.4033 - 131ms/epoch - 12ms/step\n",
            "Epoch 50/400\n",
            "11/11 - 0s - loss: 0.4398 - accuracy: 0.7905 - f1_m: 0.6854 - precision_m: 0.8030 - recall_m: 0.6894 - val_loss: 0.5904 - val_accuracy: 0.7333 - val_f1_m: 0.5933 - val_precision_m: 0.6833 - val_recall_m: 0.5367 - 131ms/epoch - 12ms/step\n",
            "Epoch 51/400\n",
            "11/11 - 0s - loss: 0.4454 - accuracy: 0.7619 - f1_m: 0.6640 - precision_m: 0.7000 - recall_m: 0.6639 - val_loss: 0.6018 - val_accuracy: 0.7111 - val_f1_m: 0.5276 - val_precision_m: 0.6833 - val_recall_m: 0.4533 - 195ms/epoch - 18ms/step\n",
            "Epoch 52/400\n",
            "11/11 - 0s - loss: 0.4237 - accuracy: 0.8190 - f1_m: 0.7126 - precision_m: 0.7749 - recall_m: 0.7258 - val_loss: 0.6190 - val_accuracy: 0.7333 - val_f1_m: 0.6276 - val_precision_m: 0.6867 - val_recall_m: 0.5867 - 154ms/epoch - 14ms/step\n",
            "Epoch 53/400\n",
            "11/11 - 0s - loss: 0.4242 - accuracy: 0.8095 - f1_m: 0.6986 - precision_m: 0.7667 - recall_m: 0.6561 - val_loss: 0.5923 - val_accuracy: 0.7333 - val_f1_m: 0.5876 - val_precision_m: 0.6833 - val_recall_m: 0.5200 - 133ms/epoch - 12ms/step\n",
            "Epoch 54/400\n",
            "11/11 - 0s - loss: 0.4197 - accuracy: 0.8000 - f1_m: 0.7123 - precision_m: 0.8000 - recall_m: 0.7121 - val_loss: 0.6137 - val_accuracy: 0.7778 - val_f1_m: 0.6888 - val_precision_m: 0.7167 - val_recall_m: 0.6767 - 146ms/epoch - 13ms/step\n",
            "Epoch 55/400\n",
            "11/11 - 0s - loss: 0.4143 - accuracy: 0.8190 - f1_m: 0.7116 - precision_m: 0.7727 - recall_m: 0.7485 - val_loss: 0.6134 - val_accuracy: 0.7333 - val_f1_m: 0.5600 - val_precision_m: 0.7500 - val_recall_m: 0.4700 - 103ms/epoch - 9ms/step\n",
            "Epoch 56/400\n",
            "11/11 - 0s - loss: 0.4400 - accuracy: 0.7714 - f1_m: 0.6758 - precision_m: 0.7922 - recall_m: 0.6955 - val_loss: 0.5885 - val_accuracy: 0.7333 - val_f1_m: 0.5876 - val_precision_m: 0.6833 - val_recall_m: 0.5200 - 128ms/epoch - 12ms/step\n",
            "Epoch 57/400\n",
            "11/11 - 0s - loss: 0.3939 - accuracy: 0.8000 - f1_m: 0.6914 - precision_m: 0.8076 - recall_m: 0.6424 - val_loss: 0.6008 - val_accuracy: 0.7556 - val_f1_m: 0.6410 - val_precision_m: 0.7167 - val_recall_m: 0.5867 - 147ms/epoch - 13ms/step\n",
            "Epoch 58/400\n",
            "11/11 - 0s - loss: 0.3953 - accuracy: 0.8381 - f1_m: 0.7831 - precision_m: 0.8697 - recall_m: 0.7846 - val_loss: 0.5953 - val_accuracy: 0.7556 - val_f1_m: 0.6233 - val_precision_m: 0.7000 - val_recall_m: 0.5700 - 210ms/epoch - 19ms/step\n",
            "Epoch 59/400\n",
            "11/11 - 0s - loss: 0.3929 - accuracy: 0.8095 - f1_m: 0.6951 - precision_m: 0.7385 - recall_m: 0.7370 - val_loss: 0.6274 - val_accuracy: 0.7111 - val_f1_m: 0.5000 - val_precision_m: 0.7500 - val_recall_m: 0.4033 - 150ms/epoch - 14ms/step\n",
            "Epoch 60/400\n",
            "11/11 - 0s - loss: 0.4233 - accuracy: 0.7905 - f1_m: 0.6232 - precision_m: 0.7848 - recall_m: 0.5909 - val_loss: 0.6166 - val_accuracy: 0.8000 - val_f1_m: 0.7310 - val_precision_m: 0.6929 - val_recall_m: 0.7833 - 160ms/epoch - 15ms/step\n",
            "Epoch 61/400\n",
            "11/11 - 0s - loss: 0.3988 - accuracy: 0.7905 - f1_m: 0.6584 - precision_m: 0.7037 - recall_m: 0.6900 - val_loss: 0.6301 - val_accuracy: 0.7111 - val_f1_m: 0.6021 - val_precision_m: 0.6167 - val_recall_m: 0.6100 - 107ms/epoch - 10ms/step\n",
            "Epoch 62/400\n",
            "11/11 - 0s - loss: 0.3834 - accuracy: 0.8381 - f1_m: 0.7524 - precision_m: 0.8128 - recall_m: 0.7370 - val_loss: 0.6120 - val_accuracy: 0.7556 - val_f1_m: 0.6633 - val_precision_m: 0.7033 - val_recall_m: 0.6367 - 141ms/epoch - 13ms/step\n",
            "Epoch 63/400\n",
            "11/11 - 0s - loss: 0.4043 - accuracy: 0.8381 - f1_m: 0.6952 - precision_m: 0.8455 - recall_m: 0.6554 - val_loss: 0.6902 - val_accuracy: 0.6444 - val_f1_m: 0.5893 - val_precision_m: 0.5400 - val_recall_m: 0.6767 - 164ms/epoch - 15ms/step\n",
            "Epoch 64/400\n",
            "11/11 - 0s - loss: 0.3750 - accuracy: 0.8286 - f1_m: 0.7307 - precision_m: 0.6785 - recall_m: 0.8273 - val_loss: 0.6462 - val_accuracy: 0.7333 - val_f1_m: 0.5600 - val_precision_m: 0.7500 - val_recall_m: 0.4700 - 89ms/epoch - 8ms/step\n",
            "Epoch 65/400\n",
            "11/11 - 0s - loss: 0.4400 - accuracy: 0.8095 - f1_m: 0.6897 - precision_m: 0.9091 - recall_m: 0.6227 - val_loss: 0.6846 - val_accuracy: 0.7333 - val_f1_m: 0.7031 - val_precision_m: 0.6250 - val_recall_m: 0.8333 - 83ms/epoch - 8ms/step\n",
            "Epoch 66/400\n",
            "11/11 - 0s - loss: 0.3849 - accuracy: 0.8095 - f1_m: 0.7680 - precision_m: 0.7571 - recall_m: 0.8409 - val_loss: 0.6015 - val_accuracy: 0.7778 - val_f1_m: 0.6433 - val_precision_m: 0.8000 - val_recall_m: 0.5700 - 61ms/epoch - 6ms/step\n",
            "Epoch 67/400\n",
            "11/11 - 0s - loss: 0.3511 - accuracy: 0.8476 - f1_m: 0.7425 - precision_m: 0.8318 - recall_m: 0.7126 - val_loss: 0.7491 - val_accuracy: 0.6889 - val_f1_m: 0.6743 - val_precision_m: 0.5844 - val_recall_m: 0.8333 - 66ms/epoch - 6ms/step\n",
            "Epoch 68/400\n",
            "11/11 - 0s - loss: 0.3749 - accuracy: 0.8286 - f1_m: 0.7433 - precision_m: 0.8527 - recall_m: 0.7682 - val_loss: 0.6664 - val_accuracy: 0.7111 - val_f1_m: 0.4603 - val_precision_m: 0.6000 - val_recall_m: 0.3967 - 80ms/epoch - 7ms/step\n",
            "Epoch 69/400\n",
            "11/11 - 0s - loss: 0.4639 - accuracy: 0.7905 - f1_m: 0.6668 - precision_m: 0.7846 - recall_m: 0.6212 - val_loss: 0.6334 - val_accuracy: 0.7111 - val_f1_m: 0.6333 - val_precision_m: 0.5795 - val_recall_m: 0.7167 - 68ms/epoch - 6ms/step\n",
            "Epoch 70/400\n",
            "11/11 - 0s - loss: 0.3771 - accuracy: 0.7905 - f1_m: 0.7043 - precision_m: 0.7738 - recall_m: 0.6952 - val_loss: 0.6558 - val_accuracy: 0.7333 - val_f1_m: 0.6276 - val_precision_m: 0.6867 - val_recall_m: 0.5867 - 84ms/epoch - 8ms/step\n",
            "Epoch 71/400\n",
            "11/11 - 0s - loss: 0.3797 - accuracy: 0.8190 - f1_m: 0.6491 - precision_m: 0.7227 - recall_m: 0.6439 - val_loss: 0.5972 - val_accuracy: 0.8000 - val_f1_m: 0.6718 - val_precision_m: 0.7167 - val_recall_m: 0.6500 - 81ms/epoch - 7ms/step\n",
            "Epoch 72/400\n",
            "11/11 - 0s - loss: 0.3455 - accuracy: 0.8286 - f1_m: 0.7563 - precision_m: 0.7871 - recall_m: 0.7924 - val_loss: 0.6151 - val_accuracy: 0.7556 - val_f1_m: 0.6233 - val_precision_m: 0.7000 - val_recall_m: 0.5700 - 63ms/epoch - 6ms/step\n",
            "Epoch 73/400\n",
            "11/11 - 0s - loss: 0.3543 - accuracy: 0.8095 - f1_m: 0.6925 - precision_m: 0.7424 - recall_m: 0.6773 - val_loss: 0.6071 - val_accuracy: 0.7556 - val_f1_m: 0.6367 - val_precision_m: 0.6767 - val_recall_m: 0.6100 - 63ms/epoch - 6ms/step\n",
            "Epoch 74/400\n",
            "11/11 - 0s - loss: 0.3384 - accuracy: 0.8286 - f1_m: 0.6778 - precision_m: 0.7697 - recall_m: 0.6364 - val_loss: 0.6861 - val_accuracy: 0.7333 - val_f1_m: 0.6524 - val_precision_m: 0.6833 - val_recall_m: 0.6367 - 64ms/epoch - 6ms/step\n",
            "Epoch 75/400\n",
            "11/11 - 0s - loss: 0.3542 - accuracy: 0.8286 - f1_m: 0.6781 - precision_m: 0.6864 - recall_m: 0.7134 - val_loss: 0.6164 - val_accuracy: 0.8000 - val_f1_m: 0.6900 - val_precision_m: 0.7100 - val_recall_m: 0.6767 - 79ms/epoch - 7ms/step\n",
            "Epoch 76/400\n",
            "11/11 - 0s - loss: 0.3476 - accuracy: 0.8667 - f1_m: 0.8248 - precision_m: 0.8983 - recall_m: 0.8076 - val_loss: 0.6139 - val_accuracy: 0.7556 - val_f1_m: 0.6710 - val_precision_m: 0.6595 - val_recall_m: 0.7167 - 81ms/epoch - 7ms/step\n",
            "Epoch 77/400\n",
            "11/11 - 0s - loss: 0.2979 - accuracy: 0.8667 - f1_m: 0.8012 - precision_m: 0.8833 - recall_m: 0.7794 - val_loss: 0.6469 - val_accuracy: 0.7111 - val_f1_m: 0.6669 - val_precision_m: 0.6233 - val_recall_m: 0.7433 - 79ms/epoch - 7ms/step\n",
            "Epoch 78/400\n",
            "11/11 - 0s - loss: 0.3266 - accuracy: 0.8857 - f1_m: 0.8111 - precision_m: 0.9091 - recall_m: 0.7673 - val_loss: 0.6667 - val_accuracy: 0.7333 - val_f1_m: 0.6848 - val_precision_m: 0.6250 - val_recall_m: 0.7833 - 74ms/epoch - 7ms/step\n",
            "Epoch 79/400\n",
            "11/11 - 0s - loss: 0.2874 - accuracy: 0.8476 - f1_m: 0.8147 - precision_m: 0.8273 - recall_m: 0.8212 - val_loss: 0.6306 - val_accuracy: 0.7778 - val_f1_m: 0.6433 - val_precision_m: 0.8000 - val_recall_m: 0.5700 - 59ms/epoch - 5ms/step\n",
            "Epoch 80/400\n",
            "11/11 - 0s - loss: 0.2962 - accuracy: 0.8571 - f1_m: 0.8157 - precision_m: 0.8955 - recall_m: 0.7831 - val_loss: 0.7263 - val_accuracy: 0.6667 - val_f1_m: 0.6476 - val_precision_m: 0.5711 - val_recall_m: 0.7833 - 74ms/epoch - 7ms/step\n",
            "Epoch 81/400\n",
            "11/11 - 0s - loss: 0.2891 - accuracy: 0.8857 - f1_m: 0.7912 - precision_m: 0.8576 - recall_m: 0.7545 - val_loss: 0.6182 - val_accuracy: 0.7778 - val_f1_m: 0.6433 - val_precision_m: 0.8000 - val_recall_m: 0.5700 - 61ms/epoch - 6ms/step\n",
            "Epoch 82/400\n",
            "11/11 - 0s - loss: 0.2884 - accuracy: 0.8667 - f1_m: 0.8291 - precision_m: 0.8413 - recall_m: 0.8576 - val_loss: 0.6219 - val_accuracy: 0.7778 - val_f1_m: 0.6433 - val_precision_m: 0.8000 - val_recall_m: 0.5700 - 65ms/epoch - 6ms/step\n",
            "Epoch 83/400\n",
            "11/11 - 0s - loss: 0.2899 - accuracy: 0.8857 - f1_m: 0.8436 - precision_m: 0.9152 - recall_m: 0.8197 - val_loss: 0.6774 - val_accuracy: 0.6889 - val_f1_m: 0.6277 - val_precision_m: 0.5817 - val_recall_m: 0.7167 - 68ms/epoch - 6ms/step\n",
            "Epoch 84/400\n",
            "11/11 - 0s - loss: 0.2586 - accuracy: 0.8952 - f1_m: 0.8479 - precision_m: 0.8879 - recall_m: 0.8530 - val_loss: 0.6439 - val_accuracy: 0.7333 - val_f1_m: 0.6191 - val_precision_m: 0.7500 - val_recall_m: 0.5700 - 68ms/epoch - 6ms/step\n",
            "Epoch 85/400\n",
            "11/11 - 0s - loss: 0.2789 - accuracy: 0.8762 - f1_m: 0.7421 - precision_m: 0.8091 - recall_m: 0.7258 - val_loss: 0.6182 - val_accuracy: 0.7778 - val_f1_m: 0.6567 - val_precision_m: 0.6929 - val_recall_m: 0.6500 - 66ms/epoch - 6ms/step\n",
            "Epoch 86/400\n",
            "11/11 - 0s - loss: 0.3016 - accuracy: 0.8857 - f1_m: 0.8245 - precision_m: 0.9015 - recall_m: 0.7848 - val_loss: 0.6509 - val_accuracy: 0.7556 - val_f1_m: 0.6533 - val_precision_m: 0.6467 - val_recall_m: 0.6767 - 69ms/epoch - 6ms/step\n",
            "Epoch 87/400\n",
            "11/11 - 0s - loss: 0.2827 - accuracy: 0.8857 - f1_m: 0.8178 - precision_m: 0.9061 - recall_m: 0.7742 - val_loss: 0.7278 - val_accuracy: 0.6667 - val_f1_m: 0.6476 - val_precision_m: 0.5711 - val_recall_m: 0.7833 - 83ms/epoch - 8ms/step\n",
            "Epoch 88/400\n",
            "11/11 - 0s - loss: 0.3101 - accuracy: 0.8667 - f1_m: 0.8450 - precision_m: 0.8500 - recall_m: 0.8974 - val_loss: 0.6389 - val_accuracy: 0.8000 - val_f1_m: 0.7433 - val_precision_m: 0.7643 - val_recall_m: 0.7433 - 70ms/epoch - 6ms/step\n",
            "Epoch 89/400\n",
            "11/11 - 0s - loss: 0.2473 - accuracy: 0.9048 - f1_m: 0.8608 - precision_m: 0.8545 - recall_m: 0.8909 - val_loss: 0.6175 - val_accuracy: 0.8222 - val_f1_m: 0.6918 - val_precision_m: 0.8167 - val_recall_m: 0.6500 - 67ms/epoch - 6ms/step\n",
            "Epoch 90/400\n",
            "11/11 - 0s - loss: 0.2621 - accuracy: 0.8952 - f1_m: 0.8357 - precision_m: 0.9545 - recall_m: 0.7773 - val_loss: 0.7280 - val_accuracy: 0.6889 - val_f1_m: 0.6723 - val_precision_m: 0.6000 - val_recall_m: 0.7933 - 79ms/epoch - 7ms/step\n",
            "Epoch 91/400\n",
            "11/11 - 0s - loss: 0.2923 - accuracy: 0.8857 - f1_m: 0.8249 - precision_m: 0.8591 - recall_m: 0.8409 - val_loss: 0.6549 - val_accuracy: 0.7333 - val_f1_m: 0.6003 - val_precision_m: 0.7000 - val_recall_m: 0.5300 - 67ms/epoch - 6ms/step\n",
            "Epoch 92/400\n",
            "11/11 - 0s - loss: 0.3664 - accuracy: 0.8190 - f1_m: 0.7580 - precision_m: 0.8379 - recall_m: 0.7348 - val_loss: 0.6597 - val_accuracy: 0.7556 - val_f1_m: 0.6688 - val_precision_m: 0.6833 - val_recall_m: 0.6767 - 79ms/epoch - 7ms/step\n",
            "Epoch 93/400\n",
            "11/11 - 0s - loss: 0.2648 - accuracy: 0.9143 - f1_m: 0.8735 - precision_m: 0.9091 - recall_m: 0.8864 - val_loss: 0.6385 - val_accuracy: 0.7556 - val_f1_m: 0.6203 - val_precision_m: 0.8000 - val_recall_m: 0.5300 - 73ms/epoch - 7ms/step\n",
            "Epoch 94/400\n",
            "11/11 - 0s - loss: 0.2652 - accuracy: 0.9238 - f1_m: 0.8146 - precision_m: 0.8545 - recall_m: 0.8195 - val_loss: 0.6774 - val_accuracy: 0.7333 - val_f1_m: 0.6848 - val_precision_m: 0.6250 - val_recall_m: 0.7833 - 82ms/epoch - 7ms/step\n",
            "Epoch 95/400\n",
            "11/11 - 0s - loss: 0.2367 - accuracy: 0.9143 - f1_m: 0.8891 - precision_m: 0.9212 - recall_m: 0.8947 - val_loss: 0.6673 - val_accuracy: 0.7111 - val_f1_m: 0.6372 - val_precision_m: 0.5917 - val_recall_m: 0.7167 - 72ms/epoch - 7ms/step\n",
            "Epoch 96/400\n",
            "11/11 - 0s - loss: 0.2318 - accuracy: 0.8952 - f1_m: 0.8475 - precision_m: 0.8758 - recall_m: 0.8788 - val_loss: 0.6155 - val_accuracy: 0.7556 - val_f1_m: 0.6300 - val_precision_m: 0.6767 - val_recall_m: 0.6100 - 79ms/epoch - 7ms/step\n",
            "Epoch 97/400\n",
            "11/11 - 0s - loss: 0.2449 - accuracy: 0.9143 - f1_m: 0.8558 - precision_m: 0.9318 - recall_m: 0.8247 - val_loss: 0.6323 - val_accuracy: 0.7556 - val_f1_m: 0.6791 - val_precision_m: 0.7500 - val_recall_m: 0.6367 - 64ms/epoch - 6ms/step\n",
            "Epoch 98/400\n",
            "11/11 - 0s - loss: 0.2367 - accuracy: 0.9143 - f1_m: 0.8978 - precision_m: 0.9394 - recall_m: 0.8818 - val_loss: 0.6213 - val_accuracy: 0.8000 - val_f1_m: 0.6767 - val_precision_m: 0.7929 - val_recall_m: 0.6500 - 76ms/epoch - 7ms/step\n",
            "Epoch 99/400\n",
            "11/11 - 0s - loss: 0.2366 - accuracy: 0.9143 - f1_m: 0.8854 - precision_m: 0.9318 - recall_m: 0.8749 - val_loss: 0.7507 - val_accuracy: 0.7111 - val_f1_m: 0.6405 - val_precision_m: 0.5995 - val_recall_m: 0.7167 - 63ms/epoch - 6ms/step\n",
            "Epoch 100/400\n",
            "11/11 - 0s - loss: 0.2323 - accuracy: 0.8952 - f1_m: 0.8229 - precision_m: 0.8961 - recall_m: 0.8318 - val_loss: 0.6747 - val_accuracy: 0.8000 - val_f1_m: 0.7248 - val_precision_m: 0.8143 - val_recall_m: 0.6767 - 67ms/epoch - 6ms/step\n",
            "Epoch 101/400\n",
            "11/11 - 0s - loss: 0.1934 - accuracy: 0.9714 - f1_m: 0.9545 - precision_m: 1.0000 - recall_m: 0.9286 - val_loss: 0.6711 - val_accuracy: 0.7556 - val_f1_m: 0.6633 - val_precision_m: 0.6429 - val_recall_m: 0.7167 - 75ms/epoch - 7ms/step\n",
            "Epoch 102/400\n",
            "11/11 - 0s - loss: 0.1704 - accuracy: 0.9429 - f1_m: 0.9348 - precision_m: 0.9394 - recall_m: 0.9394 - val_loss: 0.6416 - val_accuracy: 0.7556 - val_f1_m: 0.6300 - val_precision_m: 0.7700 - val_recall_m: 0.5700 - 64ms/epoch - 6ms/step\n",
            "Epoch 103/400\n",
            "11/11 - 0s - loss: 0.2416 - accuracy: 0.8667 - f1_m: 0.7518 - precision_m: 0.7932 - recall_m: 0.7758 - val_loss: 0.6575 - val_accuracy: 0.7778 - val_f1_m: 0.6638 - val_precision_m: 0.7750 - val_recall_m: 0.6500 - 65ms/epoch - 6ms/step\n",
            "Epoch 104/400\n",
            "11/11 - 0s - loss: 0.1950 - accuracy: 0.9143 - f1_m: 0.8494 - precision_m: 0.9773 - recall_m: 0.7697 - val_loss: 0.8303 - val_accuracy: 0.7333 - val_f1_m: 0.7111 - val_precision_m: 0.6444 - val_recall_m: 0.8333 - 62ms/epoch - 6ms/step\n",
            "Epoch 105/400\n",
            "11/11 - 0s - loss: 0.2228 - accuracy: 0.9143 - f1_m: 0.8299 - precision_m: 0.8649 - recall_m: 0.8197 - val_loss: 0.6662 - val_accuracy: 0.7556 - val_f1_m: 0.6203 - val_precision_m: 0.8000 - val_recall_m: 0.5300 - 85ms/epoch - 8ms/step\n",
            "Epoch 106/400\n",
            "11/11 - 0s - loss: 0.2714 - accuracy: 0.9143 - f1_m: 0.8681 - precision_m: 0.9318 - recall_m: 0.8409 - val_loss: 0.6205 - val_accuracy: 0.8222 - val_f1_m: 0.6918 - val_precision_m: 0.8167 - val_recall_m: 0.6500 - 77ms/epoch - 7ms/step\n",
            "Epoch 107/400\n",
            "11/11 - 0s - loss: 0.1985 - accuracy: 0.9238 - f1_m: 0.9006 - precision_m: 0.9015 - recall_m: 0.9258 - val_loss: 0.6424 - val_accuracy: 0.7556 - val_f1_m: 0.6690 - val_precision_m: 0.6567 - val_recall_m: 0.7167 - 65ms/epoch - 6ms/step\n",
            "Epoch 108/400\n",
            "11/11 - 0s - loss: 0.1742 - accuracy: 0.9619 - f1_m: 0.9585 - precision_m: 1.0000 - recall_m: 0.9258 - val_loss: 0.7078 - val_accuracy: 0.7556 - val_f1_m: 0.7038 - val_precision_m: 0.6583 - val_recall_m: 0.7833 - 63ms/epoch - 6ms/step\n",
            "Epoch 109/400\n",
            "11/11 - 0s - loss: 0.1844 - accuracy: 0.9429 - f1_m: 0.9336 - precision_m: 0.9409 - recall_m: 0.9409 - val_loss: 0.7703 - val_accuracy: 0.8000 - val_f1_m: 0.7248 - val_precision_m: 0.8143 - val_recall_m: 0.6767 - 69ms/epoch - 6ms/step\n",
            "Epoch 110/400\n",
            "11/11 - 0s - loss: 0.2257 - accuracy: 0.9238 - f1_m: 0.8606 - precision_m: 0.8939 - recall_m: 0.8636 - val_loss: 0.6958 - val_accuracy: 0.7778 - val_f1_m: 0.6552 - val_precision_m: 0.6867 - val_recall_m: 0.6500 - 65ms/epoch - 6ms/step\n",
            "Epoch 111/400\n",
            "11/11 - 0s - loss: 0.2935 - accuracy: 0.8857 - f1_m: 0.8165 - precision_m: 0.8788 - recall_m: 0.8485 - val_loss: 0.8101 - val_accuracy: 0.6889 - val_f1_m: 0.6643 - val_precision_m: 0.6011 - val_recall_m: 0.7833 - 70ms/epoch - 6ms/step\n",
            "Epoch 112/400\n",
            "11/11 - 0s - loss: 0.1840 - accuracy: 0.9048 - f1_m: 0.8680 - precision_m: 0.9409 - recall_m: 0.8500 - val_loss: 0.7047 - val_accuracy: 0.7778 - val_f1_m: 0.7305 - val_precision_m: 0.7250 - val_recall_m: 0.7833 - 67ms/epoch - 6ms/step\n",
            "Epoch 113/400\n",
            "11/11 - 0s - loss: 0.1516 - accuracy: 0.9524 - f1_m: 0.9251 - precision_m: 0.9697 - recall_m: 0.9091 - val_loss: 0.7224 - val_accuracy: 0.7556 - val_f1_m: 0.7038 - val_precision_m: 0.6583 - val_recall_m: 0.7833 - 84ms/epoch - 8ms/step\n",
            "Epoch 114/400\n",
            "11/11 - 0s - loss: 0.1457 - accuracy: 0.9619 - f1_m: 0.9457 - precision_m: 0.9818 - recall_m: 0.9242 - val_loss: 0.7014 - val_accuracy: 0.8000 - val_f1_m: 0.7318 - val_precision_m: 0.7000 - val_recall_m: 0.7833 - 82ms/epoch - 7ms/step\n",
            "Epoch 115/400\n",
            "11/11 - 0s - loss: 0.1548 - accuracy: 0.9714 - f1_m: 0.9587 - precision_m: 1.0000 - recall_m: 0.9288 - val_loss: 0.7858 - val_accuracy: 0.7111 - val_f1_m: 0.6777 - val_precision_m: 0.6183 - val_recall_m: 0.7833 - 67ms/epoch - 6ms/step\n",
            "Epoch 116/400\n",
            "11/11 - 0s - loss: 0.1899 - accuracy: 0.9238 - f1_m: 0.8514 - precision_m: 0.9167 - recall_m: 0.8561 - val_loss: 0.7138 - val_accuracy: 0.8000 - val_f1_m: 0.7238 - val_precision_m: 0.7750 - val_recall_m: 0.7167 - 77ms/epoch - 7ms/step\n",
            "Epoch 117/400\n",
            "11/11 - 0s - loss: 0.1613 - accuracy: 0.9524 - f1_m: 0.9163 - precision_m: 0.9318 - recall_m: 0.9364 - val_loss: 0.7196 - val_accuracy: 0.8222 - val_f1_m: 0.7638 - val_precision_m: 0.7750 - val_recall_m: 0.7833 - 63ms/epoch - 6ms/step\n",
            "Epoch 118/400\n",
            "11/11 - 0s - loss: 0.2213 - accuracy: 0.9143 - f1_m: 0.8134 - precision_m: 0.8779 - recall_m: 0.7894 - val_loss: 0.9066 - val_accuracy: 0.6667 - val_f1_m: 0.6476 - val_precision_m: 0.5711 - val_recall_m: 0.7833 - 72ms/epoch - 7ms/step\n",
            "Epoch 119/400\n",
            "11/11 - 0s - loss: 0.2055 - accuracy: 0.9143 - f1_m: 0.8788 - precision_m: 0.9361 - recall_m: 0.8606 - val_loss: 0.6863 - val_accuracy: 0.8000 - val_f1_m: 0.7100 - val_precision_m: 0.7767 - val_recall_m: 0.6767 - 76ms/epoch - 7ms/step\n",
            "Epoch 120/400\n",
            "11/11 - 0s - loss: 0.1919 - accuracy: 0.9238 - f1_m: 0.8146 - precision_m: 0.8152 - recall_m: 0.8348 - val_loss: 0.6971 - val_accuracy: 0.8000 - val_f1_m: 0.7155 - val_precision_m: 0.7833 - val_recall_m: 0.6767 - 66ms/epoch - 6ms/step\n",
            "Epoch 121/400\n",
            "11/11 - 0s - loss: 0.2073 - accuracy: 0.9238 - f1_m: 0.8870 - precision_m: 0.9636 - recall_m: 0.8727 - val_loss: 0.9218 - val_accuracy: 0.7111 - val_f1_m: 0.6833 - val_precision_m: 0.6344 - val_recall_m: 0.7833 - 80ms/epoch - 7ms/step\n",
            "Epoch 122/400\n",
            "11/11 - 0s - loss: 0.2031 - accuracy: 0.9238 - f1_m: 0.8195 - precision_m: 0.8864 - recall_m: 0.7833 - val_loss: 0.8226 - val_accuracy: 0.7333 - val_f1_m: 0.6929 - val_precision_m: 0.6444 - val_recall_m: 0.7833 - 84ms/epoch - 8ms/step\n",
            "Epoch 123/400\n",
            "11/11 - 0s - loss: 0.1843 - accuracy: 0.9333 - f1_m: 0.8946 - precision_m: 0.9091 - recall_m: 0.9061 - val_loss: 0.7798 - val_accuracy: 0.7556 - val_f1_m: 0.6633 - val_precision_m: 0.6429 - val_recall_m: 0.7167 - 63ms/epoch - 6ms/step\n",
            "Epoch 124/400\n",
            "11/11 - 0s - loss: 0.1488 - accuracy: 0.9810 - f1_m: 0.9717 - precision_m: 1.0000 - recall_m: 0.9515 - val_loss: 0.8230 - val_accuracy: 0.8222 - val_f1_m: 0.7638 - val_precision_m: 0.7750 - val_recall_m: 0.7833 - 66ms/epoch - 6ms/step\n",
            "Epoch 125/400\n",
            "11/11 - 0s - loss: 0.1540 - accuracy: 0.9333 - f1_m: 0.8887 - precision_m: 0.9242 - recall_m: 0.8712 - val_loss: 0.9175 - val_accuracy: 0.7111 - val_f1_m: 0.6833 - val_precision_m: 0.6344 - val_recall_m: 0.7833 - 79ms/epoch - 7ms/step\n",
            "Epoch 126/400\n",
            "11/11 - 0s - loss: 0.1590 - accuracy: 0.9429 - f1_m: 0.9194 - precision_m: 0.9470 - recall_m: 0.9113 - val_loss: 0.7501 - val_accuracy: 0.8000 - val_f1_m: 0.7238 - val_precision_m: 0.7750 - val_recall_m: 0.7167 - 80ms/epoch - 7ms/step\n",
            "Epoch 127/400\n",
            "11/11 - 0s - loss: 0.1340 - accuracy: 0.9619 - f1_m: 0.9505 - precision_m: 0.9773 - recall_m: 0.9364 - val_loss: 0.7776 - val_accuracy: 0.7778 - val_f1_m: 0.7038 - val_precision_m: 0.7417 - val_recall_m: 0.7167 - 63ms/epoch - 6ms/step\n",
            "Epoch 128/400\n",
            "11/11 - 0s - loss: 0.1245 - accuracy: 0.9619 - f1_m: 0.9437 - precision_m: 0.9773 - recall_m: 0.9318 - val_loss: 0.7373 - val_accuracy: 0.7778 - val_f1_m: 0.6767 - val_precision_m: 0.6595 - val_recall_m: 0.7167 - 77ms/epoch - 7ms/step\n",
            "Epoch 129/400\n",
            "11/11 - 0s - loss: 0.1176 - accuracy: 0.9429 - f1_m: 0.9140 - precision_m: 0.9545 - recall_m: 0.9052 - val_loss: 0.8494 - val_accuracy: 0.7556 - val_f1_m: 0.7038 - val_precision_m: 0.6583 - val_recall_m: 0.7833 - 68ms/epoch - 6ms/step\n",
            "Epoch 130/400\n",
            "11/11 - 0s - loss: 0.1643 - accuracy: 0.9429 - f1_m: 0.8931 - precision_m: 0.8939 - recall_m: 0.9470 - val_loss: 0.7858 - val_accuracy: 0.7778 - val_f1_m: 0.6555 - val_precision_m: 0.7833 - val_recall_m: 0.6100 - 63ms/epoch - 6ms/step\n",
            "Epoch 131/400\n",
            "11/11 - 0s - loss: 0.1505 - accuracy: 0.9333 - f1_m: 0.8467 - precision_m: 0.8606 - recall_m: 0.8500 - val_loss: 0.9215 - val_accuracy: 0.7111 - val_f1_m: 0.6933 - val_precision_m: 0.6178 - val_recall_m: 0.8333 - 78ms/epoch - 7ms/step\n",
            "Epoch 132/400\n",
            "11/11 - 0s - loss: 0.1648 - accuracy: 0.9333 - f1_m: 0.8993 - precision_m: 0.9394 - recall_m: 0.8864 - val_loss: 0.7373 - val_accuracy: 0.7778 - val_f1_m: 0.7038 - val_precision_m: 0.7417 - val_recall_m: 0.7167 - 62ms/epoch - 6ms/step\n",
            "Epoch 133/400\n",
            "11/11 - 0s - loss: 0.1099 - accuracy: 0.9619 - f1_m: 0.9490 - precision_m: 0.9773 - recall_m: 0.9288 - val_loss: 0.7699 - val_accuracy: 0.7778 - val_f1_m: 0.7038 - val_precision_m: 0.7417 - val_recall_m: 0.7167 - 65ms/epoch - 6ms/step\n",
            "Epoch 134/400\n",
            "11/11 - 0s - loss: 0.0944 - accuracy: 0.9905 - f1_m: 0.9008 - precision_m: 0.9091 - recall_m: 0.8939 - val_loss: 0.8197 - val_accuracy: 0.7556 - val_f1_m: 0.6633 - val_precision_m: 0.6429 - val_recall_m: 0.7167 - 69ms/epoch - 6ms/step\n",
            "Epoch 135/400\n",
            "11/11 - 0s - loss: 0.0952 - accuracy: 0.9810 - f1_m: 0.8831 - precision_m: 0.9091 - recall_m: 0.8636 - val_loss: 0.7543 - val_accuracy: 0.8000 - val_f1_m: 0.6767 - val_precision_m: 0.7929 - val_recall_m: 0.6500 - 67ms/epoch - 6ms/step\n",
            "Epoch 136/400\n",
            "11/11 - 0s - loss: 0.1096 - accuracy: 0.9524 - f1_m: 0.9129 - precision_m: 0.9545 - recall_m: 0.9091 - val_loss: 1.0580 - val_accuracy: 0.7111 - val_f1_m: 0.6933 - val_precision_m: 0.6178 - val_recall_m: 0.8333 - 67ms/epoch - 6ms/step\n",
            "Epoch 137/400\n",
            "11/11 - 0s - loss: 0.1539 - accuracy: 0.9429 - f1_m: 0.9344 - precision_m: 0.9773 - recall_m: 0.9061 - val_loss: 0.8411 - val_accuracy: 0.7111 - val_f1_m: 0.6500 - val_precision_m: 0.7011 - val_recall_m: 0.7167 - 66ms/epoch - 6ms/step\n",
            "Epoch 138/400\n",
            "11/11 - 0s - loss: 0.1925 - accuracy: 0.9238 - f1_m: 0.8757 - precision_m: 0.8506 - recall_m: 0.9545 - val_loss: 0.8206 - val_accuracy: 0.8000 - val_f1_m: 0.6769 - val_precision_m: 0.8333 - val_recall_m: 0.6100 - 68ms/epoch - 6ms/step\n",
            "Epoch 139/400\n",
            "11/11 - 0s - loss: 0.1170 - accuracy: 0.9619 - f1_m: 0.9367 - precision_m: 0.9773 - recall_m: 0.9188 - val_loss: 1.0043 - val_accuracy: 0.6889 - val_f1_m: 0.6243 - val_precision_m: 0.5850 - val_recall_m: 0.7167 - 68ms/epoch - 6ms/step\n",
            "Epoch 140/400\n",
            "11/11 - 0s - loss: 0.1493 - accuracy: 0.9619 - f1_m: 0.9534 - precision_m: 0.9667 - recall_m: 0.9515 - val_loss: 0.8029 - val_accuracy: 0.7778 - val_f1_m: 0.7033 - val_precision_m: 0.7643 - val_recall_m: 0.6767 - 78ms/epoch - 7ms/step\n",
            "Epoch 141/400\n",
            "11/11 - 0s - loss: 0.0990 - accuracy: 0.9714 - f1_m: 0.9616 - precision_m: 1.0000 - recall_m: 0.9333 - val_loss: 0.9228 - val_accuracy: 0.7111 - val_f1_m: 0.6833 - val_precision_m: 0.6344 - val_recall_m: 0.7833 - 66ms/epoch - 6ms/step\n",
            "Epoch 142/400\n",
            "11/11 - 0s - loss: 0.1076 - accuracy: 0.9619 - f1_m: 0.9587 - precision_m: 1.0000 - recall_m: 0.9288 - val_loss: 0.8418 - val_accuracy: 0.7333 - val_f1_m: 0.6505 - val_precision_m: 0.6250 - val_recall_m: 0.7167 - 66ms/epoch - 6ms/step\n",
            "Epoch 143/400\n",
            "11/11 - 0s - loss: 0.0988 - accuracy: 0.9905 - f1_m: 0.9870 - precision_m: 1.0000 - recall_m: 0.9773 - val_loss: 0.8102 - val_accuracy: 0.7778 - val_f1_m: 0.6638 - val_precision_m: 0.7750 - val_recall_m: 0.6500 - 86ms/epoch - 8ms/step\n",
            "Epoch 144/400\n",
            "11/11 - 0s - loss: 0.2136 - accuracy: 0.9143 - f1_m: 0.9114 - precision_m: 0.9333 - recall_m: 0.9253 - val_loss: 0.8774 - val_accuracy: 0.7556 - val_f1_m: 0.6781 - val_precision_m: 0.7143 - val_recall_m: 0.6767 - 77ms/epoch - 7ms/step\n",
            "Epoch 145/400\n",
            "11/11 - 0s - loss: 0.2244 - accuracy: 0.9143 - f1_m: 0.8703 - precision_m: 0.9394 - recall_m: 0.8455 - val_loss: 0.8540 - val_accuracy: 0.8000 - val_f1_m: 0.7238 - val_precision_m: 0.7750 - val_recall_m: 0.7167 - 62ms/epoch - 6ms/step\n",
            "Epoch 146/400\n",
            "11/11 - 0s - loss: 0.1834 - accuracy: 0.9524 - f1_m: 0.9459 - precision_m: 0.9394 - recall_m: 0.9621 - val_loss: 0.7589 - val_accuracy: 0.8222 - val_f1_m: 0.7367 - val_precision_m: 0.7929 - val_recall_m: 0.7167 - 77ms/epoch - 7ms/step\n",
            "Epoch 147/400\n",
            "11/11 - 0s - loss: 0.1621 - accuracy: 0.9524 - f1_m: 0.9466 - precision_m: 1.0000 - recall_m: 0.9045 - val_loss: 0.8656 - val_accuracy: 0.7556 - val_f1_m: 0.6633 - val_precision_m: 0.6429 - val_recall_m: 0.7167 - 64ms/epoch - 6ms/step\n",
            "Epoch 148/400\n",
            "11/11 - 0s - loss: 0.1032 - accuracy: 0.9524 - f1_m: 0.9383 - precision_m: 0.9545 - recall_m: 0.9439 - val_loss: 0.8565 - val_accuracy: 0.7333 - val_f1_m: 0.6929 - val_precision_m: 0.6444 - val_recall_m: 0.7833 - 82ms/epoch - 7ms/step\n",
            "Epoch 149/400\n",
            "11/11 - 0s - loss: 0.1022 - accuracy: 0.9619 - f1_m: 0.8781 - precision_m: 0.8939 - recall_m: 0.8727 - val_loss: 0.8166 - val_accuracy: 0.8000 - val_f1_m: 0.6985 - val_precision_m: 0.7667 - val_recall_m: 0.7167 - 66ms/epoch - 6ms/step\n",
            "Epoch 150/400\n",
            "11/11 - 0s - loss: 0.1465 - accuracy: 0.9429 - f1_m: 0.9194 - precision_m: 0.9318 - recall_m: 0.9416 - val_loss: 0.9475 - val_accuracy: 0.7111 - val_f1_m: 0.6324 - val_precision_m: 0.6500 - val_recall_m: 0.6367 - 85ms/epoch - 8ms/step\n",
            "Epoch 151/400\n",
            "11/11 - 0s - loss: 0.1729 - accuracy: 0.9143 - f1_m: 0.8689 - precision_m: 0.9773 - recall_m: 0.8219 - val_loss: 1.1289 - val_accuracy: 0.7333 - val_f1_m: 0.6538 - val_precision_m: 0.6329 - val_recall_m: 0.7167 - 82ms/epoch - 7ms/step\n",
            "Epoch 152/400\n",
            "11/11 - 0s - loss: 0.2197 - accuracy: 0.9048 - f1_m: 0.7957 - precision_m: 0.7900 - recall_m: 0.8422 - val_loss: 0.8883 - val_accuracy: 0.8000 - val_f1_m: 0.6700 - val_precision_m: 0.8100 - val_recall_m: 0.6100 - 80ms/epoch - 7ms/step\n",
            "Epoch 153/400\n",
            "11/11 - 0s - loss: 0.1468 - accuracy: 0.9524 - f1_m: 0.9331 - precision_m: 0.9545 - recall_m: 0.9212 - val_loss: 0.7856 - val_accuracy: 0.8000 - val_f1_m: 0.6918 - val_precision_m: 0.6833 - val_recall_m: 0.7167 - 65ms/epoch - 6ms/step\n",
            "Epoch 154/400\n",
            "11/11 - 0s - loss: 0.1009 - accuracy: 0.9619 - f1_m: 0.8757 - precision_m: 0.8939 - recall_m: 0.8658 - val_loss: 0.8918 - val_accuracy: 0.7778 - val_f1_m: 0.6818 - val_precision_m: 0.7367 - val_recall_m: 0.7167 - 78ms/epoch - 7ms/step\n",
            "Epoch 155/400\n",
            "11/11 - 0s - loss: 0.1019 - accuracy: 0.9810 - f1_m: 0.9769 - precision_m: 0.9818 - recall_m: 0.9773 - val_loss: 0.7297 - val_accuracy: 0.8000 - val_f1_m: 0.6767 - val_precision_m: 0.7929 - val_recall_m: 0.6500 - 87ms/epoch - 8ms/step\n",
            "Epoch 156/400\n",
            "11/11 - 0s - loss: 0.0900 - accuracy: 0.9714 - f1_m: 0.9635 - precision_m: 1.0000 - recall_m: 0.9364 - val_loss: 0.8368 - val_accuracy: 0.7556 - val_f1_m: 0.7038 - val_precision_m: 0.6583 - val_recall_m: 0.7833 - 73ms/epoch - 7ms/step\n",
            "Epoch 157/400\n",
            "11/11 - 0s - loss: 0.0866 - accuracy: 0.9905 - f1_m: 0.9917 - precision_m: 1.0000 - recall_m: 0.9848 - val_loss: 0.8537 - val_accuracy: 0.8000 - val_f1_m: 0.7238 - val_precision_m: 0.7750 - val_recall_m: 0.7167 - 65ms/epoch - 6ms/step\n",
            "Epoch 158/400\n",
            "11/11 - 0s - loss: 0.0796 - accuracy: 0.9810 - f1_m: 0.9688 - precision_m: 1.0000 - recall_m: 0.9470 - val_loss: 0.7860 - val_accuracy: 0.8000 - val_f1_m: 0.7238 - val_precision_m: 0.7750 - val_recall_m: 0.7167 - 61ms/epoch - 6ms/step\n",
            "Epoch 159/400\n",
            "11/11 - 0s - loss: 0.1153 - accuracy: 0.9429 - f1_m: 0.9295 - precision_m: 0.9773 - recall_m: 0.9052 - val_loss: 1.1899 - val_accuracy: 0.6889 - val_f1_m: 0.6243 - val_precision_m: 0.5850 - val_recall_m: 0.7167 - 71ms/epoch - 6ms/step\n",
            "Epoch 160/400\n",
            "11/11 - 0s - loss: 0.1680 - accuracy: 0.9429 - f1_m: 0.8430 - precision_m: 0.8597 - recall_m: 0.8485 - val_loss: 0.8013 - val_accuracy: 0.8444 - val_f1_m: 0.7518 - val_precision_m: 0.8167 - val_recall_m: 0.7167 - 66ms/epoch - 6ms/step\n",
            "Epoch 161/400\n",
            "11/11 - 0s - loss: 0.1194 - accuracy: 0.9619 - f1_m: 0.9333 - precision_m: 0.9242 - recall_m: 0.9697 - val_loss: 0.7585 - val_accuracy: 0.8222 - val_f1_m: 0.6918 - val_precision_m: 0.8167 - val_recall_m: 0.6500 - 66ms/epoch - 6ms/step\n",
            "Epoch 162/400\n",
            "11/11 - 0s - loss: 0.0844 - accuracy: 0.9810 - f1_m: 0.9740 - precision_m: 1.0000 - recall_m: 0.9545 - val_loss: 0.9439 - val_accuracy: 0.7333 - val_f1_m: 0.6943 - val_precision_m: 0.6483 - val_recall_m: 0.7833 - 80ms/epoch - 7ms/step\n",
            "Epoch 163/400\n",
            "11/11 - 0s - loss: 0.0801 - accuracy: 0.9905 - f1_m: 0.9870 - precision_m: 1.0000 - recall_m: 0.9773 - val_loss: 0.8843 - val_accuracy: 0.8222 - val_f1_m: 0.7638 - val_precision_m: 0.7750 - val_recall_m: 0.7833 - 77ms/epoch - 7ms/step\n",
            "Epoch 164/400\n",
            "11/11 - 0s - loss: 0.0613 - accuracy: 0.9905 - f1_m: 0.9870 - precision_m: 1.0000 - recall_m: 0.9773 - val_loss: 0.7760 - val_accuracy: 0.8000 - val_f1_m: 0.6767 - val_precision_m: 0.7929 - val_recall_m: 0.6500 - 85ms/epoch - 8ms/step\n",
            "Epoch 165/400\n",
            "11/11 - 0s - loss: 0.0497 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.8000 - val_f1_m: 0.7433 - val_precision_m: 0.7429 - val_recall_m: 0.7833 - 67ms/epoch - 6ms/step\n",
            "Epoch 166/400\n",
            "11/11 - 0s - loss: 0.0589 - accuracy: 0.9905 - f1_m: 0.9917 - precision_m: 1.0000 - recall_m: 0.9848 - val_loss: 0.8520 - val_accuracy: 0.8222 - val_f1_m: 0.7367 - val_precision_m: 0.7929 - val_recall_m: 0.7167 - 63ms/epoch - 6ms/step\n",
            "Epoch 167/400\n",
            "11/11 - 0s - loss: 0.0469 - accuracy: 0.9905 - f1_m: 0.9870 - precision_m: 1.0000 - recall_m: 0.9773 - val_loss: 0.9248 - val_accuracy: 0.7333 - val_f1_m: 0.6943 - val_precision_m: 0.6483 - val_recall_m: 0.7833 - 75ms/epoch - 7ms/step\n",
            "Epoch 168/400\n",
            "11/11 - 0s - loss: 0.0588 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.8275 - val_accuracy: 0.8444 - val_f1_m: 0.7718 - val_precision_m: 0.7833 - val_recall_m: 0.7833 - 65ms/epoch - 6ms/step\n",
            "Epoch 169/400\n",
            "11/11 - 0s - loss: 0.0466 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.9210 - val_accuracy: 0.8222 - val_f1_m: 0.7585 - val_precision_m: 0.7667 - val_recall_m: 0.7833 - 62ms/epoch - 6ms/step\n",
            "Epoch 170/400\n",
            "11/11 - 0s - loss: 0.0560 - accuracy: 0.9905 - f1_m: 0.9899 - precision_m: 1.0000 - recall_m: 0.9818 - val_loss: 0.9476 - val_accuracy: 0.7333 - val_f1_m: 0.6929 - val_precision_m: 0.6444 - val_recall_m: 0.7833 - 92ms/epoch - 8ms/step\n",
            "Epoch 171/400\n",
            "11/11 - 0s - loss: 0.0520 - accuracy: 0.9905 - f1_m: 0.9818 - precision_m: 0.9697 - recall_m: 1.0000 - val_loss: 0.9091 - val_accuracy: 0.7778 - val_f1_m: 0.7305 - val_precision_m: 0.7250 - val_recall_m: 0.7833 - 73ms/epoch - 7ms/step\n",
            "Epoch 172/400\n",
            "11/11 - 0s - loss: 0.0498 - accuracy: 0.9905 - f1_m: 0.8909 - precision_m: 0.9091 - recall_m: 0.8788 - val_loss: 0.9328 - val_accuracy: 0.7778 - val_f1_m: 0.7305 - val_precision_m: 0.7250 - val_recall_m: 0.7833 - 68ms/epoch - 6ms/step\n",
            "Epoch 173/400\n",
            "11/11 - 0s - loss: 0.0388 - accuracy: 0.9905 - f1_m: 0.9870 - precision_m: 1.0000 - recall_m: 0.9773 - val_loss: 0.9175 - val_accuracy: 0.7778 - val_f1_m: 0.7305 - val_precision_m: 0.7250 - val_recall_m: 0.7833 - 81ms/epoch - 7ms/step\n",
            "Epoch 174/400\n",
            "11/11 - 0s - loss: 0.0404 - accuracy: 0.9905 - f1_m: 0.9818 - precision_m: 0.9697 - recall_m: 1.0000 - val_loss: 0.8822 - val_accuracy: 0.8000 - val_f1_m: 0.7238 - val_precision_m: 0.7750 - val_recall_m: 0.7167 - 93ms/epoch - 8ms/step\n",
            "Epoch 175/400\n",
            "11/11 - 0s - loss: 0.0746 - accuracy: 0.9619 - f1_m: 0.9194 - precision_m: 0.9773 - recall_m: 0.8961 - val_loss: 1.0295 - val_accuracy: 0.6889 - val_f1_m: 0.6643 - val_precision_m: 0.6011 - val_recall_m: 0.7833 - 85ms/epoch - 8ms/step\n",
            "Epoch 176/400\n",
            "11/11 - 0s - loss: 0.0393 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.8835 - val_accuracy: 0.8222 - val_f1_m: 0.6918 - val_precision_m: 0.8167 - val_recall_m: 0.6500 - 72ms/epoch - 7ms/step\n",
            "Epoch 177/400\n",
            "11/11 - 0s - loss: 0.0472 - accuracy: 0.9905 - f1_m: 0.9870 - precision_m: 1.0000 - recall_m: 0.9773 - val_loss: 0.9587 - val_accuracy: 0.7556 - val_f1_m: 0.7038 - val_precision_m: 0.6583 - val_recall_m: 0.7833 - 69ms/epoch - 6ms/step\n",
            "Epoch 178/400\n",
            "11/11 - 0s - loss: 0.0413 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 0.8868 - val_accuracy: 0.8444 - val_f1_m: 0.7518 - val_precision_m: 0.8167 - val_recall_m: 0.7167 - 69ms/epoch - 6ms/step\n",
            "Epoch 179/400\n",
            "11/11 - 0s - loss: 0.0352 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.0211 - val_accuracy: 0.7333 - val_f1_m: 0.6929 - val_precision_m: 0.6444 - val_recall_m: 0.7833 - 70ms/epoch - 6ms/step\n",
            "Epoch 180/400\n",
            "11/11 - 0s - loss: 0.0397 - accuracy: 0.9905 - f1_m: 0.9697 - precision_m: 1.0000 - recall_m: 0.9545 - val_loss: 0.8821 - val_accuracy: 0.8000 - val_f1_m: 0.7238 - val_precision_m: 0.7750 - val_recall_m: 0.7167 - 63ms/epoch - 6ms/step\n",
            "Epoch 181/400\n",
            "11/11 - 0s - loss: 0.0419 - accuracy: 0.9905 - f1_m: 0.9870 - precision_m: 1.0000 - recall_m: 0.9773 - val_loss: 1.1742 - val_accuracy: 0.7111 - val_f1_m: 0.6833 - val_precision_m: 0.6344 - val_recall_m: 0.7833 - 67ms/epoch - 6ms/step\n",
            "Epoch 182/400\n",
            "11/11 - 0s - loss: 0.0719 - accuracy: 0.9714 - f1_m: 0.9618 - precision_m: 0.9643 - recall_m: 0.9697 - val_loss: 0.8633 - val_accuracy: 0.8222 - val_f1_m: 0.6918 - val_precision_m: 0.8167 - val_recall_m: 0.6500 - 68ms/epoch - 6ms/step\n",
            "Epoch 183/400\n",
            "11/11 - 0s - loss: 0.0591 - accuracy: 0.9810 - f1_m: 0.9688 - precision_m: 0.9697 - recall_m: 0.9773 - val_loss: 0.8396 - val_accuracy: 0.8000 - val_f1_m: 0.7269 - val_precision_m: 0.7333 - val_recall_m: 0.7433 - 77ms/epoch - 7ms/step\n",
            "Epoch 184/400\n",
            "11/11 - 0s - loss: 0.0465 - accuracy: 0.9905 - f1_m: 0.9818 - precision_m: 1.0000 - recall_m: 0.9697 - val_loss: 1.1575 - val_accuracy: 0.7111 - val_f1_m: 0.6833 - val_precision_m: 0.6344 - val_recall_m: 0.7833 - 63ms/epoch - 6ms/step\n",
            "Epoch 185/400\n",
            "11/11 - 0s - loss: 0.0640 - accuracy: 0.9714 - f1_m: 0.9680 - precision_m: 0.9545 - recall_m: 0.9886 - val_loss: 0.9196 - val_accuracy: 0.7778 - val_f1_m: 0.7148 - val_precision_m: 0.7143 - val_recall_m: 0.7433 - 80ms/epoch - 7ms/step\n",
            "Epoch 186/400\n",
            "11/11 - 0s - loss: 0.0602 - accuracy: 0.9905 - f1_m: 0.9930 - precision_m: 1.0000 - recall_m: 0.9870 - val_loss: 0.9910 - val_accuracy: 0.8000 - val_f1_m: 0.7433 - val_precision_m: 0.7429 - val_recall_m: 0.7833 - 89ms/epoch - 8ms/step\n",
            "Epoch 187/400\n",
            "11/11 - 0s - loss: 0.0416 - accuracy: 0.9905 - f1_m: 0.9899 - precision_m: 1.0000 - recall_m: 0.9818 - val_loss: 0.9530 - val_accuracy: 0.8222 - val_f1_m: 0.7681 - val_precision_m: 0.7095 - val_recall_m: 0.8500 - 71ms/epoch - 6ms/step\n",
            "Epoch 188/400\n",
            "11/11 - 0s - loss: 0.0450 - accuracy: 0.9905 - f1_m: 0.9899 - precision_m: 1.0000 - recall_m: 0.9818 - val_loss: 1.1274 - val_accuracy: 0.7333 - val_f1_m: 0.6929 - val_precision_m: 0.6444 - val_recall_m: 0.7833 - 86ms/epoch - 8ms/step\n",
            "Epoch 189/400\n",
            "11/11 - 0s - loss: 0.0534 - accuracy: 0.9905 - f1_m: 0.9870 - precision_m: 1.0000 - recall_m: 0.9773 - val_loss: 0.9115 - val_accuracy: 0.8444 - val_f1_m: 0.7718 - val_precision_m: 0.7833 - val_recall_m: 0.7833 - 75ms/epoch - 7ms/step\n",
            "Epoch 190/400\n",
            "11/11 - 0s - loss: 0.0317 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.8000 - val_f1_m: 0.7438 - val_precision_m: 0.7417 - val_recall_m: 0.7833 - 64ms/epoch - 6ms/step\n",
            "Epoch 191/400\n",
            "11/11 - 0s - loss: 0.0405 - accuracy: 0.9905 - f1_m: 0.9899 - precision_m: 1.0000 - recall_m: 0.9818 - val_loss: 1.0338 - val_accuracy: 0.7111 - val_f1_m: 0.6738 - val_precision_m: 0.6111 - val_recall_m: 0.7833 - 65ms/epoch - 6ms/step\n",
            "Epoch 192/400\n",
            "11/11 - 0s - loss: 0.0232 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.9415 - val_accuracy: 0.8667 - val_f1_m: 0.7918 - val_precision_m: 0.8167 - val_recall_m: 0.7833 - 70ms/epoch - 6ms/step\n",
            "Epoch 193/400\n",
            "11/11 - 0s - loss: 0.0322 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.0016 - val_accuracy: 0.8000 - val_f1_m: 0.7438 - val_precision_m: 0.7417 - val_recall_m: 0.7833 - 83ms/epoch - 8ms/step\n",
            "Epoch 194/400\n",
            "11/11 - 0s - loss: 0.0310 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 0.9638 - val_accuracy: 0.8222 - val_f1_m: 0.6918 - val_precision_m: 0.8167 - val_recall_m: 0.6500 - 64ms/epoch - 6ms/step\n",
            "Epoch 195/400\n",
            "11/11 - 0s - loss: 0.0334 - accuracy: 0.9905 - f1_m: 0.9818 - precision_m: 1.0000 - recall_m: 0.9697 - val_loss: 1.1839 - val_accuracy: 0.7333 - val_f1_m: 0.7095 - val_precision_m: 0.6311 - val_recall_m: 0.8500 - 71ms/epoch - 6ms/step\n",
            "Epoch 196/400\n",
            "11/11 - 0s - loss: 0.0348 - accuracy: 0.9905 - f1_m: 0.8990 - precision_m: 0.8909 - recall_m: 0.9091 - val_loss: 1.0857 - val_accuracy: 0.8000 - val_f1_m: 0.7238 - val_precision_m: 0.7750 - val_recall_m: 0.7167 - 69ms/epoch - 6ms/step\n",
            "Epoch 197/400\n",
            "11/11 - 0s - loss: 0.0369 - accuracy: 0.9905 - f1_m: 0.9917 - precision_m: 1.0000 - recall_m: 0.9848 - val_loss: 1.0790 - val_accuracy: 0.7556 - val_f1_m: 0.6976 - val_precision_m: 0.6429 - val_recall_m: 0.7833 - 70ms/epoch - 6ms/step\n",
            "Epoch 198/400\n",
            "11/11 - 0s - loss: 0.0404 - accuracy: 0.9905 - f1_m: 0.9870 - precision_m: 1.0000 - recall_m: 0.9773 - val_loss: 1.0289 - val_accuracy: 0.7778 - val_f1_m: 0.7305 - val_precision_m: 0.7250 - val_recall_m: 0.7833 - 68ms/epoch - 6ms/step\n",
            "Epoch 199/400\n",
            "11/11 - 0s - loss: 0.0278 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.8222 - val_f1_m: 0.7481 - val_precision_m: 0.7429 - val_recall_m: 0.7833 - 67ms/epoch - 6ms/step\n",
            "Epoch 200/400\n",
            "11/11 - 0s - loss: 0.0250 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1139 - val_accuracy: 0.7556 - val_f1_m: 0.7038 - val_precision_m: 0.6583 - val_recall_m: 0.7833 - 80ms/epoch - 7ms/step\n",
            "Epoch 201/400\n",
            "11/11 - 0s - loss: 0.0282 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 0.9635 - val_accuracy: 0.8222 - val_f1_m: 0.7300 - val_precision_m: 0.8100 - val_recall_m: 0.6767 - 93ms/epoch - 8ms/step\n",
            "Epoch 202/400\n",
            "11/11 - 0s - loss: 0.1521 - accuracy: 0.9333 - f1_m: 0.9072 - precision_m: 0.9141 - recall_m: 0.9318 - val_loss: 0.9899 - val_accuracy: 0.7778 - val_f1_m: 0.6888 - val_precision_m: 0.7167 - val_recall_m: 0.6767 - 67ms/epoch - 6ms/step\n",
            "Epoch 203/400\n",
            "11/11 - 0s - loss: 0.1759 - accuracy: 0.9524 - f1_m: 0.9437 - precision_m: 1.0000 - recall_m: 0.9091 - val_loss: 1.5378 - val_accuracy: 0.7111 - val_f1_m: 0.6921 - val_precision_m: 0.6111 - val_recall_m: 0.8333 - 75ms/epoch - 7ms/step\n",
            "Epoch 204/400\n",
            "11/11 - 0s - loss: 0.1012 - accuracy: 0.9238 - f1_m: 0.8875 - precision_m: 0.9030 - recall_m: 0.8931 - val_loss: 1.0724 - val_accuracy: 0.7778 - val_f1_m: 0.7338 - val_precision_m: 0.6617 - val_recall_m: 0.8500 - 70ms/epoch - 6ms/step\n",
            "Epoch 205/400\n",
            "11/11 - 0s - loss: 0.0875 - accuracy: 0.9619 - f1_m: 0.9557 - precision_m: 0.9394 - recall_m: 0.9818 - val_loss: 1.1250 - val_accuracy: 0.8222 - val_f1_m: 0.7318 - val_precision_m: 0.7833 - val_recall_m: 0.7167 - 65ms/epoch - 6ms/step\n",
            "Epoch 206/400\n",
            "11/11 - 0s - loss: 0.1364 - accuracy: 0.9333 - f1_m: 0.8986 - precision_m: 0.9621 - recall_m: 0.8788 - val_loss: 1.1191 - val_accuracy: 0.7333 - val_f1_m: 0.6943 - val_precision_m: 0.6483 - val_recall_m: 0.7833 - 73ms/epoch - 7ms/step\n",
            "Epoch 207/400\n",
            "11/11 - 0s - loss: 0.0492 - accuracy: 0.9810 - f1_m: 0.9769 - precision_m: 0.9773 - recall_m: 0.9818 - val_loss: 0.9360 - val_accuracy: 0.8222 - val_f1_m: 0.7567 - val_precision_m: 0.7595 - val_recall_m: 0.7833 - 70ms/epoch - 6ms/step\n",
            "Epoch 208/400\n",
            "11/11 - 0s - loss: 0.0691 - accuracy: 0.9810 - f1_m: 0.8990 - precision_m: 0.9091 - recall_m: 0.8909 - val_loss: 0.9641 - val_accuracy: 0.8444 - val_f1_m: 0.7518 - val_precision_m: 0.8167 - val_recall_m: 0.7167 - 89ms/epoch - 8ms/step\n",
            "Epoch 209/400\n",
            "11/11 - 0s - loss: 0.1081 - accuracy: 0.9619 - f1_m: 0.8697 - precision_m: 0.8409 - recall_m: 0.9091 - val_loss: 0.9576 - val_accuracy: 0.8222 - val_f1_m: 0.6918 - val_precision_m: 0.8167 - val_recall_m: 0.6500 - 65ms/epoch - 6ms/step\n",
            "Epoch 210/400\n",
            "11/11 - 0s - loss: 0.0989 - accuracy: 0.9619 - f1_m: 0.8759 - precision_m: 0.9091 - recall_m: 0.8500 - val_loss: 1.2047 - val_accuracy: 0.7111 - val_f1_m: 0.6929 - val_precision_m: 0.6011 - val_recall_m: 0.8500 - 82ms/epoch - 7ms/step\n",
            "Epoch 211/400\n",
            "11/11 - 0s - loss: 0.1234 - accuracy: 0.9524 - f1_m: 0.9377 - precision_m: 0.9697 - recall_m: 0.9242 - val_loss: 0.9688 - val_accuracy: 0.8222 - val_f1_m: 0.7318 - val_precision_m: 0.7833 - val_recall_m: 0.7167 - 72ms/epoch - 7ms/step\n",
            "Epoch 212/400\n",
            "11/11 - 0s - loss: 0.1726 - accuracy: 0.9333 - f1_m: 0.9276 - precision_m: 0.9227 - recall_m: 0.9409 - val_loss: 0.9447 - val_accuracy: 0.8000 - val_f1_m: 0.6981 - val_precision_m: 0.7833 - val_recall_m: 0.6367 - 78ms/epoch - 7ms/step\n",
            "Epoch 213/400\n",
            "11/11 - 0s - loss: 0.1328 - accuracy: 0.9619 - f1_m: 0.8697 - precision_m: 0.8939 - recall_m: 0.8561 - val_loss: 1.0538 - val_accuracy: 0.7556 - val_f1_m: 0.7100 - val_precision_m: 0.7143 - val_recall_m: 0.7433 - 75ms/epoch - 7ms/step\n",
            "Epoch 214/400\n",
            "11/11 - 0s - loss: 0.1193 - accuracy: 0.9619 - f1_m: 0.9383 - precision_m: 0.9773 - recall_m: 0.9212 - val_loss: 1.2134 - val_accuracy: 0.7111 - val_f1_m: 0.6681 - val_precision_m: 0.5950 - val_recall_m: 0.7833 - 74ms/epoch - 7ms/step\n",
            "Epoch 215/400\n",
            "11/11 - 0s - loss: 0.1857 - accuracy: 0.9333 - f1_m: 0.7950 - precision_m: 0.8128 - recall_m: 0.8303 - val_loss: 1.1185 - val_accuracy: 0.7556 - val_f1_m: 0.6791 - val_precision_m: 0.7500 - val_recall_m: 0.6367 - 69ms/epoch - 6ms/step\n",
            "Epoch 216/400\n",
            "11/11 - 0s - loss: 0.2110 - accuracy: 0.9143 - f1_m: 0.9022 - precision_m: 0.8758 - recall_m: 0.9636 - val_loss: 0.9502 - val_accuracy: 0.8000 - val_f1_m: 0.6985 - val_precision_m: 0.7667 - val_recall_m: 0.7167 - 85ms/epoch - 8ms/step\n",
            "Epoch 217/400\n",
            "11/11 - 0s - loss: 0.1175 - accuracy: 0.9524 - f1_m: 0.8831 - precision_m: 0.8961 - recall_m: 0.8734 - val_loss: 1.1778 - val_accuracy: 0.7556 - val_f1_m: 0.7071 - val_precision_m: 0.6662 - val_recall_m: 0.7833 - 83ms/epoch - 8ms/step\n",
            "Epoch 218/400\n",
            "11/11 - 0s - loss: 0.2108 - accuracy: 0.9429 - f1_m: 0.9245 - precision_m: 0.9461 - recall_m: 0.9394 - val_loss: 0.9708 - val_accuracy: 0.8444 - val_f1_m: 0.7518 - val_precision_m: 0.8167 - val_recall_m: 0.7167 - 89ms/epoch - 8ms/step\n",
            "Epoch 219/400\n",
            "11/11 - 0s - loss: 0.1594 - accuracy: 0.9238 - f1_m: 0.8810 - precision_m: 0.9545 - recall_m: 0.8522 - val_loss: 1.1988 - val_accuracy: 0.7556 - val_f1_m: 0.6833 - val_precision_m: 0.7310 - val_recall_m: 0.6767 - 70ms/epoch - 6ms/step\n",
            "Epoch 220/400\n",
            "11/11 - 0s - loss: 0.2411 - accuracy: 0.8857 - f1_m: 0.8292 - precision_m: 0.8727 - recall_m: 0.8219 - val_loss: 0.9937 - val_accuracy: 0.8000 - val_f1_m: 0.7585 - val_precision_m: 0.6700 - val_recall_m: 0.9000 - 78ms/epoch - 7ms/step\n",
            "Epoch 221/400\n",
            "11/11 - 0s - loss: 0.1507 - accuracy: 0.9333 - f1_m: 0.9252 - precision_m: 0.9104 - recall_m: 0.9591 - val_loss: 1.0909 - val_accuracy: 0.8000 - val_f1_m: 0.7185 - val_precision_m: 0.7667 - val_recall_m: 0.7167 - 88ms/epoch - 8ms/step\n",
            "Epoch 222/400\n",
            "11/11 - 0s - loss: 0.1452 - accuracy: 0.9619 - f1_m: 0.9517 - precision_m: 0.9697 - recall_m: 0.9461 - val_loss: 1.2690 - val_accuracy: 0.7556 - val_f1_m: 0.7038 - val_precision_m: 0.6583 - val_recall_m: 0.7833 - 79ms/epoch - 7ms/step\n",
            "Epoch 223/400\n",
            "11/11 - 0s - loss: 0.1039 - accuracy: 0.9714 - f1_m: 0.9672 - precision_m: 1.0000 - recall_m: 0.9455 - val_loss: 1.1490 - val_accuracy: 0.7778 - val_f1_m: 0.7390 - val_precision_m: 0.6767 - val_recall_m: 0.8500 - 72ms/epoch - 7ms/step\n",
            "Epoch 224/400\n",
            "11/11 - 0s - loss: 0.0734 - accuracy: 0.9619 - f1_m: 0.9645 - precision_m: 0.9667 - recall_m: 0.9688 - val_loss: 0.9956 - val_accuracy: 0.8000 - val_f1_m: 0.7355 - val_precision_m: 0.7500 - val_recall_m: 0.7433 - 83ms/epoch - 8ms/step\n",
            "Epoch 225/400\n",
            "11/11 - 0s - loss: 0.0508 - accuracy: 0.9810 - f1_m: 0.8826 - precision_m: 0.8788 - recall_m: 0.8939 - val_loss: 1.0321 - val_accuracy: 0.8000 - val_f1_m: 0.7299 - val_precision_m: 0.7167 - val_recall_m: 0.7833 - 87ms/epoch - 8ms/step\n",
            "Epoch 226/400\n",
            "11/11 - 0s - loss: 0.0401 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.7778 - val_f1_m: 0.7333 - val_precision_m: 0.6629 - val_recall_m: 0.8500 - 74ms/epoch - 7ms/step\n",
            "Epoch 227/400\n",
            "11/11 - 0s - loss: 0.0474 - accuracy: 0.9905 - f1_m: 0.9899 - precision_m: 0.9818 - recall_m: 1.0000 - val_loss: 0.9909 - val_accuracy: 0.8667 - val_f1_m: 0.7918 - val_precision_m: 0.8167 - val_recall_m: 0.7833 - 81ms/epoch - 7ms/step\n",
            "Epoch 228/400\n",
            "11/11 - 0s - loss: 0.1085 - accuracy: 0.9619 - f1_m: 0.9463 - precision_m: 0.9848 - recall_m: 0.9286 - val_loss: 1.3394 - val_accuracy: 0.7556 - val_f1_m: 0.7238 - val_precision_m: 0.6529 - val_recall_m: 0.8500 - 63ms/epoch - 6ms/step\n",
            "Epoch 229/400\n",
            "11/11 - 0s - loss: 0.0875 - accuracy: 0.9714 - f1_m: 0.9591 - precision_m: 0.9636 - recall_m: 0.9697 - val_loss: 1.0529 - val_accuracy: 0.8000 - val_f1_m: 0.7033 - val_precision_m: 0.8000 - val_recall_m: 0.6367 - 61ms/epoch - 6ms/step\n",
            "Epoch 230/400\n",
            "11/11 - 0s - loss: 0.0622 - accuracy: 0.9714 - f1_m: 0.9668 - precision_m: 1.0000 - recall_m: 0.9409 - val_loss: 1.1325 - val_accuracy: 0.7778 - val_f1_m: 0.7390 - val_precision_m: 0.6767 - val_recall_m: 0.8500 - 78ms/epoch - 7ms/step\n",
            "Epoch 231/400\n",
            "11/11 - 0s - loss: 0.0540 - accuracy: 0.9810 - f1_m: 0.9717 - precision_m: 0.9515 - recall_m: 1.0000 - val_loss: 1.0152 - val_accuracy: 0.8444 - val_f1_m: 0.7518 - val_precision_m: 0.8167 - val_recall_m: 0.7167 - 69ms/epoch - 6ms/step\n",
            "Epoch 232/400\n",
            "11/11 - 0s - loss: 0.0422 - accuracy: 0.9810 - f1_m: 0.9717 - precision_m: 1.0000 - recall_m: 0.9515 - val_loss: 1.2715 - val_accuracy: 0.7556 - val_f1_m: 0.7071 - val_precision_m: 0.6662 - val_recall_m: 0.7833 - 82ms/epoch - 7ms/step\n",
            "Epoch 233/400\n",
            "11/11 - 0s - loss: 0.0678 - accuracy: 0.9810 - f1_m: 0.9736 - precision_m: 0.9545 - recall_m: 1.0000 - val_loss: 1.0567 - val_accuracy: 0.8222 - val_f1_m: 0.7433 - val_precision_m: 0.8000 - val_recall_m: 0.7033 - 86ms/epoch - 8ms/step\n",
            "Epoch 234/400\n",
            "11/11 - 0s - loss: 0.0977 - accuracy: 0.9619 - f1_m: 0.8682 - precision_m: 0.9091 - recall_m: 0.8424 - val_loss: 1.1884 - val_accuracy: 0.8000 - val_f1_m: 0.7611 - val_precision_m: 0.6729 - val_recall_m: 0.9000 - 66ms/epoch - 6ms/step\n",
            "Epoch 235/400\n",
            "11/11 - 0s - loss: 0.0543 - accuracy: 0.9810 - f1_m: 0.9717 - precision_m: 0.9515 - recall_m: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.8444 - val_f1_m: 0.7514 - val_precision_m: 0.8600 - val_recall_m: 0.6767 - 64ms/epoch - 6ms/step\n",
            "Epoch 236/400\n",
            "11/11 - 0s - loss: 0.0630 - accuracy: 0.9810 - f1_m: 0.8788 - precision_m: 0.9091 - recall_m: 0.8636 - val_loss: 1.2243 - val_accuracy: 0.7556 - val_f1_m: 0.7032 - val_precision_m: 0.6567 - val_recall_m: 0.7833 - 77ms/epoch - 7ms/step\n",
            "Epoch 237/400\n",
            "11/11 - 0s - loss: 0.0381 - accuracy: 0.9905 - f1_m: 0.9008 - precision_m: 0.8939 - recall_m: 0.9091 - val_loss: 1.0339 - val_accuracy: 0.8444 - val_f1_m: 0.7632 - val_precision_m: 0.7667 - val_recall_m: 0.7833 - 84ms/epoch - 8ms/step\n",
            "Epoch 238/400\n",
            "11/11 - 0s - loss: 0.0273 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.8000 - val_f1_m: 0.7318 - val_precision_m: 0.7000 - val_recall_m: 0.7833 - 86ms/epoch - 8ms/step\n",
            "Epoch 239/400\n",
            "11/11 - 0s - loss: 0.0227 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.0254 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 67ms/epoch - 6ms/step\n",
            "Epoch 240/400\n",
            "11/11 - 0s - loss: 0.0193 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.0580 - val_accuracy: 0.8222 - val_f1_m: 0.7452 - val_precision_m: 0.7167 - val_recall_m: 0.7833 - 79ms/epoch - 7ms/step\n",
            "Epoch 241/400\n",
            "11/11 - 0s - loss: 0.0236 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.0312 - val_accuracy: 0.8444 - val_f1_m: 0.7632 - val_precision_m: 0.7667 - val_recall_m: 0.7833 - 75ms/epoch - 7ms/step\n",
            "Epoch 242/400\n",
            "11/11 - 0s - loss: 0.0171 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.0827 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 75ms/epoch - 7ms/step\n",
            "Epoch 243/400\n",
            "11/11 - 0s - loss: 0.0149 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.8000 - val_f1_m: 0.7318 - val_precision_m: 0.7000 - val_recall_m: 0.7833 - 83ms/epoch - 8ms/step\n",
            "Epoch 244/400\n",
            "11/11 - 0s - loss: 0.0129 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.0711 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 62ms/epoch - 6ms/step\n",
            "Epoch 245/400\n",
            "11/11 - 0s - loss: 0.0120 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.0887 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 82ms/epoch - 7ms/step\n",
            "Epoch 246/400\n",
            "11/11 - 0s - loss: 0.0117 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 63ms/epoch - 6ms/step\n",
            "Epoch 247/400\n",
            "11/11 - 0s - loss: 0.0114 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1177 - val_accuracy: 0.8000 - val_f1_m: 0.7318 - val_precision_m: 0.7000 - val_recall_m: 0.7833 - 76ms/epoch - 7ms/step\n",
            "Epoch 248/400\n",
            "11/11 - 0s - loss: 0.0109 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.0968 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 69ms/epoch - 6ms/step\n",
            "Epoch 249/400\n",
            "11/11 - 0s - loss: 0.0120 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1105 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 85ms/epoch - 8ms/step\n",
            "Epoch 250/400\n",
            "11/11 - 0s - loss: 0.0125 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.0937 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 80ms/epoch - 7ms/step\n",
            "Epoch 251/400\n",
            "11/11 - 0s - loss: 0.0114 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1118 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 78ms/epoch - 7ms/step\n",
            "Epoch 252/400\n",
            "11/11 - 0s - loss: 0.0099 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1092 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 66ms/epoch - 6ms/step\n",
            "Epoch 253/400\n",
            "11/11 - 0s - loss: 0.0094 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1346 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 66ms/epoch - 6ms/step\n",
            "Epoch 254/400\n",
            "11/11 - 0s - loss: 0.0100 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1091 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 81ms/epoch - 7ms/step\n",
            "Epoch 255/400\n",
            "11/11 - 0s - loss: 0.0096 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1252 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 80ms/epoch - 7ms/step\n",
            "Epoch 256/400\n",
            "11/11 - 0s - loss: 0.0125 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1397 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 78ms/epoch - 7ms/step\n",
            "Epoch 257/400\n",
            "11/11 - 0s - loss: 0.0107 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1388 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 79ms/epoch - 7ms/step\n",
            "Epoch 258/400\n",
            "11/11 - 0s - loss: 0.0099 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1482 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 75ms/epoch - 7ms/step\n",
            "Epoch 259/400\n",
            "11/11 - 0s - loss: 0.0082 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1246 - val_accuracy: 0.8222 - val_f1_m: 0.7452 - val_precision_m: 0.7167 - val_recall_m: 0.7833 - 68ms/epoch - 6ms/step\n",
            "Epoch 260/400\n",
            "11/11 - 0s - loss: 0.0105 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1461 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 66ms/epoch - 6ms/step\n",
            "Epoch 261/400\n",
            "11/11 - 0s - loss: 0.0096 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1725 - val_accuracy: 0.8222 - val_f1_m: 0.7452 - val_precision_m: 0.7167 - val_recall_m: 0.7833 - 69ms/epoch - 6ms/step\n",
            "Epoch 262/400\n",
            "11/11 - 0s - loss: 0.0077 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1531 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 66ms/epoch - 6ms/step\n",
            "Epoch 263/400\n",
            "11/11 - 0s - loss: 0.0076 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1620 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 80ms/epoch - 7ms/step\n",
            "Epoch 264/400\n",
            "11/11 - 0s - loss: 0.0074 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1553 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 77ms/epoch - 7ms/step\n",
            "Epoch 265/400\n",
            "11/11 - 0s - loss: 0.0076 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1601 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 79ms/epoch - 7ms/step\n",
            "Epoch 266/400\n",
            "11/11 - 0s - loss: 0.0071 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.1794 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 64ms/epoch - 6ms/step\n",
            "Epoch 267/400\n",
            "11/11 - 0s - loss: 0.0072 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1695 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 70ms/epoch - 6ms/step\n",
            "Epoch 268/400\n",
            "11/11 - 0s - loss: 0.0079 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1660 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 76ms/epoch - 7ms/step\n",
            "Epoch 269/400\n",
            "11/11 - 0s - loss: 0.0076 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1861 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 79ms/epoch - 7ms/step\n",
            "Epoch 270/400\n",
            "11/11 - 0s - loss: 0.0064 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 69ms/epoch - 6ms/step\n",
            "Epoch 271/400\n",
            "11/11 - 0s - loss: 0.0071 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2008 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 70ms/epoch - 6ms/step\n",
            "Epoch 272/400\n",
            "11/11 - 0s - loss: 0.0061 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1899 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 63ms/epoch - 6ms/step\n",
            "Epoch 273/400\n",
            "11/11 - 0s - loss: 0.0062 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2026 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 82ms/epoch - 7ms/step\n",
            "Epoch 274/400\n",
            "11/11 - 0s - loss: 0.0065 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1787 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 82ms/epoch - 7ms/step\n",
            "Epoch 275/400\n",
            "11/11 - 0s - loss: 0.0060 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2055 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 65ms/epoch - 6ms/step\n",
            "Epoch 276/400\n",
            "11/11 - 0s - loss: 0.0073 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.1964 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 65ms/epoch - 6ms/step\n",
            "Epoch 277/400\n",
            "11/11 - 0s - loss: 0.0063 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2034 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 64ms/epoch - 6ms/step\n",
            "Epoch 278/400\n",
            "11/11 - 0s - loss: 0.0054 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2072 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 68ms/epoch - 6ms/step\n",
            "Epoch 279/400\n",
            "11/11 - 0s - loss: 0.0061 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2298 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 61ms/epoch - 6ms/step\n",
            "Epoch 280/400\n",
            "11/11 - 0s - loss: 0.0059 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1991 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 76ms/epoch - 7ms/step\n",
            "Epoch 281/400\n",
            "11/11 - 0s - loss: 0.0057 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2246 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 63ms/epoch - 6ms/step\n",
            "Epoch 282/400\n",
            "11/11 - 0s - loss: 0.0059 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2295 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 68ms/epoch - 6ms/step\n",
            "Epoch 283/400\n",
            "11/11 - 0s - loss: 0.0054 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2069 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 68ms/epoch - 6ms/step\n",
            "Epoch 284/400\n",
            "11/11 - 0s - loss: 0.0057 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2569 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 79ms/epoch - 7ms/step\n",
            "Epoch 285/400\n",
            "11/11 - 0s - loss: 0.0055 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2165 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 65ms/epoch - 6ms/step\n",
            "Epoch 286/400\n",
            "11/11 - 0s - loss: 0.0057 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2312 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 77ms/epoch - 7ms/step\n",
            "Epoch 287/400\n",
            "11/11 - 0s - loss: 0.0052 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2283 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 71ms/epoch - 6ms/step\n",
            "Epoch 288/400\n",
            "11/11 - 0s - loss: 0.0057 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2453 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 71ms/epoch - 6ms/step\n",
            "Epoch 289/400\n",
            "11/11 - 0s - loss: 0.0065 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2224 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 78ms/epoch - 7ms/step\n",
            "Epoch 290/400\n",
            "11/11 - 0s - loss: 0.0056 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2383 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 83ms/epoch - 8ms/step\n",
            "Epoch 291/400\n",
            "11/11 - 0s - loss: 0.0046 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3100 - val_accuracy: 0.8000 - val_f1_m: 0.7485 - val_precision_m: 0.6867 - val_recall_m: 0.8500 - 84ms/epoch - 8ms/step\n",
            "Epoch 292/400\n",
            "11/11 - 0s - loss: 0.0050 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2201 - val_accuracy: 0.8444 - val_f1_m: 0.7632 - val_precision_m: 0.7667 - val_recall_m: 0.7833 - 68ms/epoch - 6ms/step\n",
            "Epoch 293/400\n",
            "11/11 - 0s - loss: 0.0070 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.7778 - val_f1_m: 0.7333 - val_precision_m: 0.6629 - val_recall_m: 0.8500 - 79ms/epoch - 7ms/step\n",
            "Epoch 294/400\n",
            "11/11 - 0s - loss: 0.0370 - accuracy: 0.9714 - f1_m: 0.9484 - precision_m: 0.9545 - recall_m: 0.9621 - val_loss: 1.2413 - val_accuracy: 0.8222 - val_f1_m: 0.7618 - val_precision_m: 0.7033 - val_recall_m: 0.8500 - 68ms/epoch - 6ms/step\n",
            "Epoch 295/400\n",
            "11/11 - 0s - loss: 0.0160 - accuracy: 0.9905 - f1_m: 0.9917 - precision_m: 0.9848 - recall_m: 1.0000 - val_loss: 1.2072 - val_accuracy: 0.8444 - val_f1_m: 0.7518 - val_precision_m: 0.8167 - val_recall_m: 0.7167 - 65ms/epoch - 6ms/step\n",
            "Epoch 296/400\n",
            "11/11 - 0s - loss: 0.0103 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3666 - val_accuracy: 0.8000 - val_f1_m: 0.7485 - val_precision_m: 0.6867 - val_recall_m: 0.8500 - 77ms/epoch - 7ms/step\n",
            "Epoch 297/400\n",
            "11/11 - 0s - loss: 0.0212 - accuracy: 0.9905 - f1_m: 0.9930 - precision_m: 1.0000 - recall_m: 0.9870 - val_loss: 1.3240 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 69ms/epoch - 6ms/step\n",
            "Epoch 298/400\n",
            "11/11 - 0s - loss: 0.0445 - accuracy: 0.9810 - f1_m: 0.9697 - precision_m: 0.9545 - recall_m: 1.0000 - val_loss: 1.1949 - val_accuracy: 0.8222 - val_f1_m: 0.7362 - val_precision_m: 0.8000 - val_recall_m: 0.7033 - 65ms/epoch - 6ms/step\n",
            "Epoch 299/400\n",
            "11/11 - 0s - loss: 0.2743 - accuracy: 0.9333 - f1_m: 0.9109 - precision_m: 0.9364 - recall_m: 0.9212 - val_loss: 1.3330 - val_accuracy: 0.8444 - val_f1_m: 0.7478 - val_precision_m: 0.8500 - val_recall_m: 0.6767 - 68ms/epoch - 6ms/step\n",
            "Epoch 300/400\n",
            "11/11 - 0s - loss: 0.3316 - accuracy: 0.8952 - f1_m: 0.7702 - precision_m: 0.8455 - recall_m: 0.7576 - val_loss: 2.3064 - val_accuracy: 0.6889 - val_f1_m: 0.6826 - val_precision_m: 0.6060 - val_recall_m: 0.8333 - 72ms/epoch - 7ms/step\n",
            "Epoch 301/400\n",
            "11/11 - 0s - loss: 0.6146 - accuracy: 0.7905 - f1_m: 0.6840 - precision_m: 0.7462 - recall_m: 0.7197 - val_loss: 1.2015 - val_accuracy: 0.7556 - val_f1_m: 0.6567 - val_precision_m: 0.7000 - val_recall_m: 0.6367 - 78ms/epoch - 7ms/step\n",
            "Epoch 302/400\n",
            "11/11 - 0s - loss: 0.5567 - accuracy: 0.8095 - f1_m: 0.7611 - precision_m: 0.7750 - recall_m: 0.8271 - val_loss: 1.4344 - val_accuracy: 0.8222 - val_f1_m: 0.7711 - val_precision_m: 0.7529 - val_recall_m: 0.8333 - 88ms/epoch - 8ms/step\n",
            "Epoch 303/400\n",
            "11/11 - 0s - loss: 0.4918 - accuracy: 0.8381 - f1_m: 0.7740 - precision_m: 0.8420 - recall_m: 0.8279 - val_loss: 0.8619 - val_accuracy: 0.7556 - val_f1_m: 0.6694 - val_precision_m: 0.6533 - val_recall_m: 0.7167 - 68ms/epoch - 6ms/step\n",
            "Epoch 304/400\n",
            "11/11 - 0s - loss: 0.4541 - accuracy: 0.8476 - f1_m: 0.7823 - precision_m: 0.8879 - recall_m: 0.7591 - val_loss: 1.8323 - val_accuracy: 0.6889 - val_f1_m: 0.6444 - val_precision_m: 0.5778 - val_recall_m: 0.7667 - 71ms/epoch - 6ms/step\n",
            "Epoch 305/400\n",
            "11/11 - 0s - loss: 0.5024 - accuracy: 0.8667 - f1_m: 0.8424 - precision_m: 0.8788 - recall_m: 0.8515 - val_loss: 1.2829 - val_accuracy: 0.7556 - val_f1_m: 0.7056 - val_precision_m: 0.6600 - val_recall_m: 0.7833 - 86ms/epoch - 8ms/step\n",
            "Epoch 306/400\n",
            "11/11 - 0s - loss: 0.2478 - accuracy: 0.8952 - f1_m: 0.8028 - precision_m: 0.8197 - recall_m: 0.8152 - val_loss: 1.0490 - val_accuracy: 0.8222 - val_f1_m: 0.7318 - val_precision_m: 0.7833 - val_recall_m: 0.7167 - 69ms/epoch - 6ms/step\n",
            "Epoch 307/400\n",
            "11/11 - 0s - loss: 0.1550 - accuracy: 0.9429 - f1_m: 0.9264 - precision_m: 0.9818 - recall_m: 0.8955 - val_loss: 1.1273 - val_accuracy: 0.7778 - val_f1_m: 0.7223 - val_precision_m: 0.6900 - val_recall_m: 0.7833 - 73ms/epoch - 7ms/step\n",
            "Epoch 308/400\n",
            "11/11 - 0s - loss: 0.1155 - accuracy: 0.9810 - f1_m: 0.8779 - precision_m: 0.9091 - recall_m: 0.8561 - val_loss: 1.1220 - val_accuracy: 0.8000 - val_f1_m: 0.7433 - val_precision_m: 0.7429 - val_recall_m: 0.7833 - 69ms/epoch - 6ms/step\n",
            "Epoch 309/400\n",
            "11/11 - 0s - loss: 0.0978 - accuracy: 0.9905 - f1_m: 0.9818 - precision_m: 1.0000 - recall_m: 0.9697 - val_loss: 1.1718 - val_accuracy: 0.8000 - val_f1_m: 0.7167 - val_precision_m: 0.7595 - val_recall_m: 0.7167 - 65ms/epoch - 6ms/step\n",
            "Epoch 310/400\n",
            "11/11 - 0s - loss: 0.0933 - accuracy: 0.9810 - f1_m: 0.9816 - precision_m: 0.9818 - recall_m: 0.9848 - val_loss: 1.0774 - val_accuracy: 0.8222 - val_f1_m: 0.7452 - val_precision_m: 0.7167 - val_recall_m: 0.7833 - 84ms/epoch - 8ms/step\n",
            "Epoch 311/400\n",
            "11/11 - 0s - loss: 0.0655 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1291 - val_accuracy: 0.8222 - val_f1_m: 0.7585 - val_precision_m: 0.7667 - val_recall_m: 0.7833 - 78ms/epoch - 7ms/step\n",
            "Epoch 312/400\n",
            "11/11 - 0s - loss: 0.0622 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1303 - val_accuracy: 0.8222 - val_f1_m: 0.7318 - val_precision_m: 0.7833 - val_recall_m: 0.7167 - 78ms/epoch - 7ms/step\n",
            "Epoch 313/400\n",
            "11/11 - 0s - loss: 0.0769 - accuracy: 0.9714 - f1_m: 0.9643 - precision_m: 0.9773 - recall_m: 0.9636 - val_loss: 1.2692 - val_accuracy: 0.7778 - val_f1_m: 0.7390 - val_precision_m: 0.6767 - val_recall_m: 0.8500 - 66ms/epoch - 6ms/step\n",
            "Epoch 314/400\n",
            "11/11 - 0s - loss: 0.0499 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1265 - val_accuracy: 0.8444 - val_f1_m: 0.7718 - val_precision_m: 0.7833 - val_recall_m: 0.7833 - 70ms/epoch - 6ms/step\n",
            "Epoch 315/400\n",
            "11/11 - 0s - loss: 0.0528 - accuracy: 0.9810 - f1_m: 0.9614 - precision_m: 0.9394 - recall_m: 1.0000 - val_loss: 1.1243 - val_accuracy: 0.8444 - val_f1_m: 0.7832 - val_precision_m: 0.7333 - val_recall_m: 0.8500 - 64ms/epoch - 6ms/step\n",
            "Epoch 316/400\n",
            "11/11 - 0s - loss: 0.0414 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1888 - val_accuracy: 0.8222 - val_f1_m: 0.7585 - val_precision_m: 0.7667 - val_recall_m: 0.7833 - 80ms/epoch - 7ms/step\n",
            "Epoch 317/400\n",
            "11/11 - 0s - loss: 0.0531 - accuracy: 0.9810 - f1_m: 0.9798 - precision_m: 0.9636 - recall_m: 1.0000 - val_loss: 1.1554 - val_accuracy: 0.8000 - val_f1_m: 0.7185 - val_precision_m: 0.7667 - val_recall_m: 0.7167 - 69ms/epoch - 6ms/step\n",
            "Epoch 318/400\n",
            "11/11 - 0s - loss: 0.0309 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1951 - val_accuracy: 0.8000 - val_f1_m: 0.7299 - val_precision_m: 0.7167 - val_recall_m: 0.7833 - 69ms/epoch - 6ms/step\n",
            "Epoch 319/400\n",
            "11/11 - 0s - loss: 0.0260 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1837 - val_accuracy: 0.8000 - val_f1_m: 0.7185 - val_precision_m: 0.7667 - val_recall_m: 0.7167 - 76ms/epoch - 7ms/step\n",
            "Epoch 320/400\n",
            "11/11 - 0s - loss: 0.0248 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.1878 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 76ms/epoch - 7ms/step\n",
            "Epoch 321/400\n",
            "11/11 - 0s - loss: 0.0205 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1986 - val_accuracy: 0.8000 - val_f1_m: 0.7318 - val_precision_m: 0.7000 - val_recall_m: 0.7833 - 68ms/epoch - 6ms/step\n",
            "Epoch 322/400\n",
            "11/11 - 0s - loss: 0.0199 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2132 - val_accuracy: 0.7778 - val_f1_m: 0.7223 - val_precision_m: 0.6900 - val_recall_m: 0.7833 - 81ms/epoch - 7ms/step\n",
            "Epoch 323/400\n",
            "11/11 - 0s - loss: 0.0191 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.2302 - val_accuracy: 0.7778 - val_f1_m: 0.7223 - val_precision_m: 0.6900 - val_recall_m: 0.7833 - 66ms/epoch - 6ms/step\n",
            "Epoch 324/400\n",
            "11/11 - 0s - loss: 0.0202 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2361 - val_accuracy: 0.8000 - val_f1_m: 0.7604 - val_precision_m: 0.7067 - val_recall_m: 0.8500 - 76ms/epoch - 7ms/step\n",
            "Epoch 325/400\n",
            "11/11 - 0s - loss: 0.0209 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2055 - val_accuracy: 0.8000 - val_f1_m: 0.7299 - val_precision_m: 0.7167 - val_recall_m: 0.7833 - 67ms/epoch - 6ms/step\n",
            "Epoch 326/400\n",
            "11/11 - 0s - loss: 0.0169 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3126 - val_accuracy: 0.7778 - val_f1_m: 0.7390 - val_precision_m: 0.6767 - val_recall_m: 0.8500 - 68ms/epoch - 6ms/step\n",
            "Epoch 327/400\n",
            "11/11 - 0s - loss: 0.0171 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.1865 - val_accuracy: 0.8000 - val_f1_m: 0.7299 - val_precision_m: 0.7167 - val_recall_m: 0.7833 - 75ms/epoch - 7ms/step\n",
            "Epoch 328/400\n",
            "11/11 - 0s - loss: 0.0201 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4360 - val_accuracy: 0.7556 - val_f1_m: 0.7318 - val_precision_m: 0.6700 - val_recall_m: 0.8500 - 68ms/epoch - 6ms/step\n",
            "Epoch 329/400\n",
            "11/11 - 0s - loss: 0.0420 - accuracy: 0.9905 - f1_m: 0.9899 - precision_m: 1.0000 - recall_m: 0.9818 - val_loss: 1.3573 - val_accuracy: 0.7778 - val_f1_m: 0.7390 - val_precision_m: 0.6767 - val_recall_m: 0.8500 - 63ms/epoch - 6ms/step\n",
            "Epoch 330/400\n",
            "11/11 - 0s - loss: 0.0248 - accuracy: 0.9905 - f1_m: 0.9917 - precision_m: 0.9848 - recall_m: 1.0000 - val_loss: 1.2521 - val_accuracy: 0.8444 - val_f1_m: 0.7718 - val_precision_m: 0.7833 - val_recall_m: 0.7833 - 84ms/epoch - 8ms/step\n",
            "Epoch 331/400\n",
            "11/11 - 0s - loss: 0.0279 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3408 - val_accuracy: 0.7556 - val_f1_m: 0.7238 - val_precision_m: 0.6529 - val_recall_m: 0.8500 - 73ms/epoch - 7ms/step\n",
            "Epoch 332/400\n",
            "11/11 - 0s - loss: 0.0358 - accuracy: 0.9905 - f1_m: 0.9697 - precision_m: 0.9545 - recall_m: 1.0000 - val_loss: 1.2507 - val_accuracy: 0.8222 - val_f1_m: 0.7318 - val_precision_m: 0.7833 - val_recall_m: 0.7167 - 68ms/epoch - 6ms/step\n",
            "Epoch 333/400\n",
            "11/11 - 0s - loss: 0.0415 - accuracy: 0.9714 - f1_m: 0.9587 - precision_m: 0.9818 - recall_m: 0.9470 - val_loss: 1.3891 - val_accuracy: 0.7778 - val_f1_m: 0.7390 - val_precision_m: 0.6767 - val_recall_m: 0.8500 - 65ms/epoch - 6ms/step\n",
            "Epoch 334/400\n",
            "11/11 - 0s - loss: 0.0327 - accuracy: 0.9905 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.2521 - val_accuracy: 0.8000 - val_f1_m: 0.7299 - val_precision_m: 0.7167 - val_recall_m: 0.7833 - 66ms/epoch - 6ms/step\n",
            "Epoch 335/400\n",
            "11/11 - 0s - loss: 0.0154 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3152 - val_accuracy: 0.7556 - val_f1_m: 0.7032 - val_precision_m: 0.6567 - val_recall_m: 0.7833 - 73ms/epoch - 7ms/step\n",
            "Epoch 336/400\n",
            "11/11 - 0s - loss: 0.0123 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2785 - val_accuracy: 0.8000 - val_f1_m: 0.7318 - val_precision_m: 0.7000 - val_recall_m: 0.7833 - 72ms/epoch - 7ms/step\n",
            "Epoch 337/400\n",
            "11/11 - 0s - loss: 0.0112 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2946 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 67ms/epoch - 6ms/step\n",
            "Epoch 338/400\n",
            "11/11 - 0s - loss: 0.0120 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.2844 - val_accuracy: 0.7778 - val_f1_m: 0.6918 - val_precision_m: 0.7000 - val_recall_m: 0.7167 - 74ms/epoch - 7ms/step\n",
            "Epoch 339/400\n",
            "11/11 - 0s - loss: 0.0112 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3130 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 81ms/epoch - 7ms/step\n",
            "Epoch 340/400\n",
            "11/11 - 0s - loss: 0.0101 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3123 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 84ms/epoch - 8ms/step\n",
            "Epoch 341/400\n",
            "11/11 - 0s - loss: 0.0097 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3023 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 67ms/epoch - 6ms/step\n",
            "Epoch 342/400\n",
            "11/11 - 0s - loss: 0.0091 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3286 - val_accuracy: 0.8000 - val_f1_m: 0.7604 - val_precision_m: 0.7067 - val_recall_m: 0.8500 - 76ms/epoch - 7ms/step\n",
            "Epoch 343/400\n",
            "11/11 - 0s - loss: 0.0091 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3080 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 69ms/epoch - 6ms/step\n",
            "Epoch 344/400\n",
            "11/11 - 0s - loss: 0.0090 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.3335 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 60ms/epoch - 5ms/step\n",
            "Epoch 345/400\n",
            "11/11 - 0s - loss: 0.0090 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3194 - val_accuracy: 0.8000 - val_f1_m: 0.7318 - val_precision_m: 0.7000 - val_recall_m: 0.7833 - 63ms/epoch - 6ms/step\n",
            "Epoch 346/400\n",
            "11/11 - 0s - loss: 0.0092 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3257 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 64ms/epoch - 6ms/step\n",
            "Epoch 347/400\n",
            "11/11 - 0s - loss: 0.0078 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3879 - val_accuracy: 0.7778 - val_f1_m: 0.7390 - val_precision_m: 0.6767 - val_recall_m: 0.8500 - 75ms/epoch - 7ms/step\n",
            "Epoch 348/400\n",
            "11/11 - 0s - loss: 0.0084 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.3259 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 66ms/epoch - 6ms/step\n",
            "Epoch 349/400\n",
            "11/11 - 0s - loss: 0.0088 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3330 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 71ms/epoch - 6ms/step\n",
            "Epoch 350/400\n",
            "11/11 - 0s - loss: 0.0136 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3252 - val_accuracy: 0.8000 - val_f1_m: 0.7299 - val_precision_m: 0.7167 - val_recall_m: 0.7833 - 79ms/epoch - 7ms/step\n",
            "Epoch 351/400\n",
            "11/11 - 0s - loss: 0.0095 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4039 - val_accuracy: 0.7778 - val_f1_m: 0.7390 - val_precision_m: 0.6767 - val_recall_m: 0.8500 - 69ms/epoch - 6ms/step\n",
            "Epoch 352/400\n",
            "11/11 - 0s - loss: 0.0082 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3148 - val_accuracy: 0.8222 - val_f1_m: 0.7432 - val_precision_m: 0.7333 - val_recall_m: 0.7833 - 79ms/epoch - 7ms/step\n",
            "Epoch 353/400\n",
            "11/11 - 0s - loss: 0.0087 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3770 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 79ms/epoch - 7ms/step\n",
            "Epoch 354/400\n",
            "11/11 - 0s - loss: 0.0078 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.3629 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 79ms/epoch - 7ms/step\n",
            "Epoch 355/400\n",
            "11/11 - 0s - loss: 0.0068 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3729 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 94ms/epoch - 9ms/step\n",
            "Epoch 356/400\n",
            "11/11 - 0s - loss: 0.0066 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3971 - val_accuracy: 0.8000 - val_f1_m: 0.7604 - val_precision_m: 0.7067 - val_recall_m: 0.8500 - 62ms/epoch - 6ms/step\n",
            "Epoch 357/400\n",
            "11/11 - 0s - loss: 0.0079 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3996 - val_accuracy: 0.8000 - val_f1_m: 0.7604 - val_precision_m: 0.7067 - val_recall_m: 0.8500 - 66ms/epoch - 6ms/step\n",
            "Epoch 358/400\n",
            "11/11 - 0s - loss: 0.0065 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3754 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 75ms/epoch - 7ms/step\n",
            "Epoch 359/400\n",
            "11/11 - 0s - loss: 0.0063 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.3822 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 92ms/epoch - 8ms/step\n",
            "Epoch 360/400\n",
            "11/11 - 0s - loss: 0.0060 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3636 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 76ms/epoch - 7ms/step\n",
            "Epoch 361/400\n",
            "11/11 - 0s - loss: 0.0059 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3814 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 82ms/epoch - 7ms/step\n",
            "Epoch 362/400\n",
            "11/11 - 0s - loss: 0.0060 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4145 - val_accuracy: 0.8000 - val_f1_m: 0.7604 - val_precision_m: 0.7067 - val_recall_m: 0.8500 - 86ms/epoch - 8ms/step\n",
            "Epoch 363/400\n",
            "11/11 - 0s - loss: 0.0062 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4095 - val_accuracy: 0.8000 - val_f1_m: 0.7604 - val_precision_m: 0.7067 - val_recall_m: 0.8500 - 71ms/epoch - 6ms/step\n",
            "Epoch 364/400\n",
            "11/11 - 0s - loss: 0.0057 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3711 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 67ms/epoch - 6ms/step\n",
            "Epoch 365/400\n",
            "11/11 - 0s - loss: 0.0065 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4182 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 74ms/epoch - 7ms/step\n",
            "Epoch 366/400\n",
            "11/11 - 0s - loss: 0.0085 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.3604 - val_accuracy: 0.8222 - val_f1_m: 0.7432 - val_precision_m: 0.7333 - val_recall_m: 0.7833 - 71ms/epoch - 6ms/step\n",
            "Epoch 367/400\n",
            "11/11 - 0s - loss: 0.0099 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.5065 - val_accuracy: 0.7778 - val_f1_m: 0.7390 - val_precision_m: 0.6767 - val_recall_m: 0.8500 - 75ms/epoch - 7ms/step\n",
            "Epoch 368/400\n",
            "11/11 - 0s - loss: 0.0076 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4177 - val_accuracy: 0.7778 - val_f1_m: 0.7204 - val_precision_m: 0.7067 - val_recall_m: 0.7833 - 71ms/epoch - 6ms/step\n",
            "Epoch 369/400\n",
            "11/11 - 0s - loss: 0.0064 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4107 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 70ms/epoch - 6ms/step\n",
            "Epoch 370/400\n",
            "11/11 - 0s - loss: 0.0050 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4157 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 74ms/epoch - 7ms/step\n",
            "Epoch 371/400\n",
            "11/11 - 0s - loss: 0.0053 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4284 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 80ms/epoch - 7ms/step\n",
            "Epoch 372/400\n",
            "11/11 - 0s - loss: 0.0051 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4041 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 88ms/epoch - 8ms/step\n",
            "Epoch 373/400\n",
            "11/11 - 0s - loss: 0.0050 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4315 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 89ms/epoch - 8ms/step\n",
            "Epoch 374/400\n",
            "11/11 - 0s - loss: 0.0052 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4472 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 81ms/epoch - 7ms/step\n",
            "Epoch 375/400\n",
            "11/11 - 0s - loss: 0.0047 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4089 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 71ms/epoch - 6ms/step\n",
            "Epoch 376/400\n",
            "11/11 - 0s - loss: 0.0046 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4443 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 76ms/epoch - 7ms/step\n",
            "Epoch 377/400\n",
            "11/11 - 0s - loss: 0.0046 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4705 - val_accuracy: 0.8000 - val_f1_m: 0.7604 - val_precision_m: 0.7067 - val_recall_m: 0.8500 - 72ms/epoch - 7ms/step\n",
            "Epoch 378/400\n",
            "11/11 - 0s - loss: 0.0049 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4300 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 82ms/epoch - 7ms/step\n",
            "Epoch 379/400\n",
            "11/11 - 0s - loss: 0.0045 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.4899 - val_accuracy: 0.8000 - val_f1_m: 0.7604 - val_precision_m: 0.7067 - val_recall_m: 0.8500 - 80ms/epoch - 7ms/step\n",
            "Epoch 380/400\n",
            "11/11 - 0s - loss: 0.0053 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4575 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 81ms/epoch - 7ms/step\n",
            "Epoch 381/400\n",
            "11/11 - 0s - loss: 0.0045 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4422 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 86ms/epoch - 8ms/step\n",
            "Epoch 382/400\n",
            "11/11 - 0s - loss: 0.0038 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.5093 - val_accuracy: 0.8000 - val_f1_m: 0.7604 - val_precision_m: 0.7067 - val_recall_m: 0.8500 - 71ms/epoch - 6ms/step\n",
            "Epoch 383/400\n",
            "11/11 - 0s - loss: 0.0041 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4738 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 74ms/epoch - 7ms/step\n",
            "Epoch 384/400\n",
            "11/11 - 0s - loss: 0.0036 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4690 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 78ms/epoch - 7ms/step\n",
            "Epoch 385/400\n",
            "11/11 - 0s - loss: 0.0041 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4666 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 74ms/epoch - 7ms/step\n",
            "Epoch 386/400\n",
            "11/11 - 0s - loss: 0.0039 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4819 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 96ms/epoch - 9ms/step\n",
            "Epoch 387/400\n",
            "11/11 - 0s - loss: 0.0043 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4758 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 77ms/epoch - 7ms/step\n",
            "Epoch 388/400\n",
            "11/11 - 0s - loss: 0.0040 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4859 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 64ms/epoch - 6ms/step\n",
            "Epoch 389/400\n",
            "11/11 - 0s - loss: 0.0036 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4921 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 73ms/epoch - 7ms/step\n",
            "Epoch 390/400\n",
            "11/11 - 0s - loss: 0.0036 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.5009 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 65ms/epoch - 6ms/step\n",
            "Epoch 391/400\n",
            "11/11 - 0s - loss: 0.0033 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4956 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 82ms/epoch - 7ms/step\n",
            "Epoch 392/400\n",
            "11/11 - 0s - loss: 0.0032 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.4878 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 67ms/epoch - 6ms/step\n",
            "Epoch 393/400\n",
            "11/11 - 0s - loss: 0.0036 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.5225 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 70ms/epoch - 6ms/step\n",
            "Epoch 394/400\n",
            "11/11 - 0s - loss: 0.0035 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.5063 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 88ms/epoch - 8ms/step\n",
            "Epoch 395/400\n",
            "11/11 - 0s - loss: 0.0030 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.4983 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 82ms/epoch - 7ms/step\n",
            "Epoch 396/400\n",
            "11/11 - 0s - loss: 0.0031 - accuracy: 1.0000 - f1_m: 0.9091 - precision_m: 0.9091 - recall_m: 0.9091 - val_loss: 1.5100 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 88ms/epoch - 8ms/step\n",
            "Epoch 397/400\n",
            "11/11 - 0s - loss: 0.0032 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.5091 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 72ms/epoch - 7ms/step\n",
            "Epoch 398/400\n",
            "11/11 - 0s - loss: 0.0030 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.5075 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 71ms/epoch - 6ms/step\n",
            "Epoch 399/400\n",
            "11/11 - 0s - loss: 0.0029 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.5346 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 71ms/epoch - 6ms/step\n",
            "Epoch 400/400\n",
            "11/11 - 0s - loss: 0.0033 - accuracy: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.5157 - val_accuracy: 0.8222 - val_f1_m: 0.7699 - val_precision_m: 0.7167 - val_recall_m: 0.8500 - 80ms/epoch - 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe19f37df90>"
            ]
          },
          "metadata": {},
          "execution_count": 542
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=400, verbose=2, validation_split=0.3, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy, f1_score, precision, recall = model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjQ-eLw7l0yN",
        "outputId": "b99b9b07-6664-4c71-d499-06ea5cf0bca2"
      },
      "id": "qjQ-eLw7l0yN",
      "execution_count": 543,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 - 0s - loss: 0.5008 - accuracy: 0.9492 - f1_m: 0.9174 - precision_m: 0.8958 - recall_m: 0.9416 - 28ms/epoch - 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred = y_pred >= 0.10"
      ],
      "metadata": {
        "id": "d01vUG7CkZy9"
      },
      "id": "d01vUG7CkZy9",
      "execution_count": 544,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 545,
      "id": "3d8e5e4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d8e5e4b",
        "outputId": "ab3e62d9-ae07-4d31-d5a7-db0434252938"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.915"
            ]
          },
          "metadata": {},
          "execution_count": 545
        }
      ],
      "source": [
        "round(accuracy_score(y_test, y_pred),3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_dir = 'saved_model/1'\n",
        "tf.saved_model.save(model, export_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJGhoBjvfAaD",
        "outputId": "b6938ced-8141-43e6-e700-fc419234ad54"
      },
      "id": "lJGhoBjvfAaD",
      "execution_count": 546,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.MobileNetV3Large()\n",
        "fb_model = tf.lite.TFLiteConverter.from_keras_model(model).convert()\n",
        "\n",
        "tf.lite.experimental.Analyzer.analyze(model_content=fb_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxM0mNrafam1",
        "outputId": "a25fc978-8965-4af3-cbb3-bf965587ec51"
      },
      "id": "IxM0mNrafam1",
      "execution_count": 547,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float.h5\n",
            "22667264/22661472 [==============================] - 0s 0us/step\n",
            "22675456/22661472 [==============================] - 0s 0us/step\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp3ef7n54_/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TFLite ModelAnalyzer ===\n",
            "\n",
            "Your TFLite model has '1' subgraph(s). In the subgraph description below,\n",
            "T# represents the Tensor numbers. For example, in Subgraph#0, the MUL op takes\n",
            "tensor #0 and tensor #19 as input and produces tensor #136 as output.\n",
            "\n",
            "Subgraph#0 main(T#0) -> [T#263]\n",
            "  Op#0 MUL(T#0, T#19) -> [T#136]\n",
            "  Op#1 ADD(T#136, T#18) -> [T#137]\n",
            "  Op#2 CONV_2D(T#137, T#44, T#93) -> [T#138]\n",
            "  Op#3 HARD_SWISH(T#138) -> [T#139]\n",
            "  Op#4 DEPTHWISE_CONV_2D(T#139, T#94, T#24) -> [T#140]\n",
            "  Op#5 CONV_2D(T#140, T#45, T#95) -> [T#141]\n",
            "  Op#6 ADD(T#139, T#141) -> [T#142]\n",
            "  Op#7 CONV_2D(T#142, T#46, T#25) -> [T#143]\n",
            "  Op#8 PAD(T#143, T#22) -> [T#144]\n",
            "  Op#9 DEPTHWISE_CONV_2D(T#144, T#96, T#26) -> [T#145]\n",
            "  Op#10 CONV_2D(T#145, T#47, T#97) -> [T#146]\n",
            "  Op#11 CONV_2D(T#146, T#48, T#27) -> [T#147]\n",
            "  Op#12 DEPTHWISE_CONV_2D(T#147, T#98, T#28) -> [T#148]\n",
            "  Op#13 CONV_2D(T#148, T#49, T#99) -> [T#149]\n",
            "  Op#14 ADD(T#146, T#149) -> [T#150]\n",
            "  Op#15 CONV_2D(T#150, T#50, T#29) -> [T#151]\n",
            "  Op#16 PAD(T#151, T#23) -> [T#152]\n",
            "  Op#17 DEPTHWISE_CONV_2D(T#152, T#100, T#30) -> [T#153]\n",
            "  Op#18 MEAN(T#153, T#20) -> [T#154]\n",
            "  Op#19 CONV_2D(T#154, T#51, T#3) -> [T#155]\n",
            "  Op#20 CONV_2D(T#155, T#52, T#10) -> [T#156]\n",
            "  Op#21 MUL(T#156, T#9) -> [T#157]\n",
            "  Op#22 MUL(T#153, T#157) -> [T#158]\n",
            "  Op#23 CONV_2D(T#158, T#53, T#101) -> [T#159]\n",
            "  Op#24 CONV_2D(T#159, T#54, T#31) -> [T#160]\n",
            "  Op#25 DEPTHWISE_CONV_2D(T#160, T#102, T#32) -> [T#161]\n",
            "  Op#26 MEAN(T#161, T#20) -> [T#162]\n",
            "  Op#27 CONV_2D(T#162, T#55, T#2) -> [T#163]\n",
            "  Op#28 CONV_2D(T#163, T#56, T#11) -> [T#164]\n",
            "  Op#29 MUL(T#164, T#9) -> [T#165]\n",
            "  Op#30 MUL(T#161, T#165) -> [T#166]\n",
            "  Op#31 CONV_2D(T#166, T#57, T#103) -> [T#167]\n",
            "  Op#32 ADD(T#159, T#167) -> [T#168]\n",
            "  Op#33 CONV_2D(T#168, T#58, T#33) -> [T#169]\n",
            "  Op#34 DEPTHWISE_CONV_2D(T#169, T#104, T#34) -> [T#170]\n",
            "  Op#35 MEAN(T#170, T#20) -> [T#171]\n",
            "  Op#36 CONV_2D(T#171, T#59, T#1) -> [T#172]\n",
            "  Op#37 CONV_2D(T#172, T#60, T#12) -> [T#173]\n",
            "  Op#38 MUL(T#173, T#9) -> [T#174]\n",
            "  Op#39 MUL(T#170, T#174) -> [T#175]\n",
            "  Op#40 CONV_2D(T#175, T#61, T#105) -> [T#176]\n",
            "  Op#41 ADD(T#168, T#176) -> [T#177]\n",
            "  Op#42 CONV_2D(T#177, T#62, T#106) -> [T#178]\n",
            "  Op#43 HARD_SWISH(T#178) -> [T#179]\n",
            "  Op#44 PAD(T#179, T#22) -> [T#180]\n",
            "  Op#45 DEPTHWISE_CONV_2D(T#180, T#107, T#35) -> [T#181]\n",
            "  Op#46 HARD_SWISH(T#181) -> [T#182]\n",
            "  Op#47 CONV_2D(T#182, T#63, T#108) -> [T#183]\n",
            "  Op#48 CONV_2D(T#183, T#64, T#109) -> [T#184]\n",
            "  Op#49 HARD_SWISH(T#184) -> [T#185]\n",
            "  Op#50 DEPTHWISE_CONV_2D(T#185, T#110, T#36) -> [T#186]\n",
            "  Op#51 HARD_SWISH(T#186) -> [T#187]\n",
            "  Op#52 CONV_2D(T#187, T#65, T#111) -> [T#188]\n",
            "  Op#53 ADD(T#183, T#188) -> [T#189]\n",
            "  Op#54 CONV_2D(T#189, T#66, T#112) -> [T#190]\n",
            "  Op#55 HARD_SWISH(T#190) -> [T#191]\n",
            "  Op#56 DEPTHWISE_CONV_2D(T#191, T#113, T#37) -> [T#192]\n",
            "  Op#57 HARD_SWISH(T#192) -> [T#193]\n",
            "  Op#58 CONV_2D(T#193, T#67, T#114) -> [T#194]\n",
            "  Op#59 ADD(T#189, T#194) -> [T#195]\n",
            "  Op#60 CONV_2D(T#195, T#68, T#115) -> [T#196]\n",
            "  Op#61 HARD_SWISH(T#196) -> [T#197]\n",
            "  Op#62 DEPTHWISE_CONV_2D(T#197, T#116, T#38) -> [T#198]\n",
            "  Op#63 HARD_SWISH(T#198) -> [T#199]\n",
            "  Op#64 CONV_2D(T#199, T#69, T#117) -> [T#200]\n",
            "  Op#65 ADD(T#195, T#200) -> [T#201]\n",
            "  Op#66 CONV_2D(T#201, T#70, T#118) -> [T#202]\n",
            "  Op#67 HARD_SWISH(T#202) -> [T#203]\n",
            "  Op#68 DEPTHWISE_CONV_2D(T#203, T#119, T#39) -> [T#204]\n",
            "  Op#69 HARD_SWISH(T#204) -> [T#205]\n",
            "  Op#70 MEAN(T#205, T#20) -> [T#206]\n",
            "  Op#71 CONV_2D(T#206, T#71, T#8) -> [T#207]\n",
            "  Op#72 CONV_2D(T#207, T#72, T#13) -> [T#208]\n",
            "  Op#73 MUL(T#208, T#9) -> [T#209]\n",
            "  Op#74 MUL(T#205, T#209) -> [T#210]\n",
            "  Op#75 CONV_2D(T#210, T#73, T#120) -> [T#211]\n",
            "  Op#76 CONV_2D(T#211, T#74, T#121) -> [T#212]\n",
            "  Op#77 HARD_SWISH(T#212) -> [T#213]\n",
            "  Op#78 DEPTHWISE_CONV_2D(T#213, T#122, T#40) -> [T#214]\n",
            "  Op#79 HARD_SWISH(T#214) -> [T#215]\n",
            "  Op#80 MEAN(T#215, T#20) -> [T#216]\n",
            "  Op#81 CONV_2D(T#216, T#75, T#7) -> [T#217]\n",
            "  Op#82 CONV_2D(T#217, T#76, T#14) -> [T#218]\n",
            "  Op#83 MUL(T#218, T#9) -> [T#219]\n",
            "  Op#84 MUL(T#215, T#219) -> [T#220]\n",
            "  Op#85 CONV_2D(T#220, T#77, T#123) -> [T#221]\n",
            "  Op#86 ADD(T#211, T#221) -> [T#222]\n",
            "  Op#87 CONV_2D(T#222, T#78, T#124) -> [T#223]\n",
            "  Op#88 HARD_SWISH(T#223) -> [T#224]\n",
            "  Op#89 PAD(T#224, T#23) -> [T#225]\n",
            "  Op#90 DEPTHWISE_CONV_2D(T#225, T#125, T#41) -> [T#226]\n",
            "  Op#91 HARD_SWISH(T#226) -> [T#227]\n",
            "  Op#92 MEAN(T#227, T#20) -> [T#228]\n",
            "  Op#93 CONV_2D(T#228, T#79, T#6) -> [T#229]\n",
            "  Op#94 CONV_2D(T#229, T#80, T#15) -> [T#230]\n",
            "  Op#95 MUL(T#230, T#9) -> [T#231]\n",
            "  Op#96 MUL(T#227, T#231) -> [T#232]\n",
            "  Op#97 CONV_2D(T#232, T#81, T#126) -> [T#233]\n",
            "  Op#98 CONV_2D(T#233, T#82, T#127) -> [T#234]\n",
            "  Op#99 HARD_SWISH(T#234) -> [T#235]\n",
            "  Op#100 DEPTHWISE_CONV_2D(T#235, T#128, T#42) -> [T#236]\n",
            "  Op#101 HARD_SWISH(T#236) -> [T#237]\n",
            "  Op#102 MEAN(T#237, T#20) -> [T#238]\n",
            "  Op#103 CONV_2D(T#238, T#83, T#5) -> [T#239]\n",
            "  Op#104 CONV_2D(T#239, T#84, T#16) -> [T#240]\n",
            "  Op#105 MUL(T#240, T#9) -> [T#241]\n",
            "  Op#106 MUL(T#237, T#241) -> [T#242]\n",
            "  Op#107 CONV_2D(T#242, T#85, T#129) -> [T#243]\n",
            "  Op#108 ADD(T#233, T#243) -> [T#244]\n",
            "  Op#109 CONV_2D(T#244, T#86, T#130) -> [T#245]\n",
            "  Op#110 HARD_SWISH(T#245) -> [T#246]\n",
            "  Op#111 DEPTHWISE_CONV_2D(T#246, T#131, T#43) -> [T#247]\n",
            "  Op#112 HARD_SWISH(T#247) -> [T#248]\n",
            "  Op#113 MEAN(T#248, T#20) -> [T#249]\n",
            "  Op#114 CONV_2D(T#249, T#87, T#4) -> [T#250]\n",
            "  Op#115 CONV_2D(T#250, T#88, T#17) -> [T#251]\n",
            "  Op#116 MUL(T#251, T#9) -> [T#252]\n",
            "  Op#117 MUL(T#248, T#252) -> [T#253]\n",
            "  Op#118 CONV_2D(T#253, T#89, T#132) -> [T#254]\n",
            "  Op#119 ADD(T#244, T#254) -> [T#255]\n",
            "  Op#120 CONV_2D(T#255, T#90, T#133) -> [T#256]\n",
            "  Op#121 HARD_SWISH(T#256) -> [T#257]\n",
            "  Op#122 MEAN(T#257, T#20) -> [T#258]\n",
            "  Op#123 CONV_2D(T#258, T#91, T#134) -> [T#259]\n",
            "  Op#124 HARD_SWISH(T#259) -> [T#260]\n",
            "  Op#125 CONV_2D(T#260, T#92, T#135) -> [T#261]\n",
            "  Op#126 RESHAPE(T#261, T#21) -> [T#262]\n",
            "  Op#127 SOFTMAX(T#262) -> [T#263]\n",
            "\n",
            "Tensors of Subgraph#0\n",
            "  T#0(serving_default_input_1:0) shape_signature:[-1, -1, -1, 3], type:FLOAT32\n",
            "  T#1(expanded_conv_5/squeeze_excite/Conv/bias) shape:[32], type:FLOAT32 RO 128 bytes\n",
            "  T#2(expanded_conv_4/squeeze_excite/Conv/bias) shape:[32], type:FLOAT32 RO 128 bytes\n",
            "  T#3(expanded_conv_3/squeeze_excite/Conv/bias) shape:[24], type:FLOAT32 RO 96 bytes\n",
            "  T#4(expanded_conv_14/squeeze_excite/Conv/bias) shape:[240], type:FLOAT32 RO 960 bytes\n",
            "  T#5(expanded_conv_13/squeeze_excite/Conv/bias) shape:[240], type:FLOAT32 RO 960 bytes\n",
            "  T#6(expanded_conv_12/squeeze_excite/Conv/bias) shape:[168], type:FLOAT32 RO 672 bytes\n",
            "  T#7(expanded_conv_11/squeeze_excite/Conv/bias) shape:[168], type:FLOAT32 RO 672 bytes\n",
            "  T#8(expanded_conv_10/squeeze_excite/Conv/bias) shape:[120], type:FLOAT32 RO 480 bytes\n",
            "  T#9(MobilenetV3large/tf.math.multiply/Mul/y) shape:[], type:FLOAT32 RO 4 bytes\n",
            "  T#10(MobilenetV3large/re_lu_8/Relu6;MobilenetV3large/tf.__operators__.add_1/AddV2;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D;expanded_conv_3/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[72], type:FLOAT32 RO 288 bytes\n",
            "  T#11(MobilenetV3large/re_lu_11/Relu6;MobilenetV3large/tf.__operators__.add_2/AddV2;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv_1/Conv2D;expanded_conv_4/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[120], type:FLOAT32 RO 480 bytes\n",
            "  T#12(MobilenetV3large/re_lu_14/Relu6;MobilenetV3large/tf.__operators__.add_3/AddV2;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv_1/Conv2D;expanded_conv_5/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[120], type:FLOAT32 RO 480 bytes\n",
            "  T#13(MobilenetV3large/re_lu_25/Relu6;MobilenetV3large/tf.__operators__.add_14/AddV2;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D;expanded_conv_10/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[480], type:FLOAT32 RO 1920 bytes\n",
            "  T#14(MobilenetV3large/re_lu_28/Relu6;MobilenetV3large/tf.__operators__.add_17/AddV2;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv_1/Conv2D;expanded_conv_11/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[672], type:FLOAT32 RO 2688 bytes\n",
            "  T#15(MobilenetV3large/re_lu_31/Relu6;MobilenetV3large/tf.__operators__.add_20/AddV2;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;expanded_conv_12/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[672], type:FLOAT32 RO 2688 bytes\n",
            "  T#16(MobilenetV3large/re_lu_34/Relu6;MobilenetV3large/tf.__operators__.add_23/AddV2;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv_1/Conv2D;expanded_conv_13/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[960], type:FLOAT32 RO 3840 bytes\n",
            "  T#17(MobilenetV3large/re_lu_37/Relu6;MobilenetV3large/tf.__operators__.add_26/AddV2;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv_1/Conv2D;expanded_conv_14/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y) shape:[960], type:FLOAT32 RO 3840 bytes\n",
            "  T#18(MobilenetV3large/rescaling/Cast_1/x) shape:[], type:FLOAT32 RO 4 bytes\n",
            "  T#19(MobilenetV3large/rescaling/Cast/x) shape:[], type:FLOAT32 RO 4 bytes\n",
            "  T#20(MobilenetV3large/expanded_conv_10/squeeze_excite/AvgPool/Mean/reduction_indices) shape:[2], type:INT32 RO 8 bytes\n",
            "  T#21(MobilenetV3large/flatten/Const) shape:[2], type:INT32 RO 8 bytes\n",
            "  T#22(MobilenetV3large/expanded_conv_1/depthwise/pad/Pad/paddings) shape:[4, 2], type:INT32 RO 32 bytes\n",
            "  T#23(MobilenetV3large/expanded_conv_12/depthwise/pad/Pad/paddings) shape:[4, 2], type:INT32 RO 32 bytes\n",
            "  T#24(MobilenetV3large/expanded_conv/depthwise/BatchNorm/FusedBatchNormV3) shape:[16], type:FLOAT32 RO 64 bytes\n",
            "  T#25(MobilenetV3large/expanded_conv_1/expand/BatchNorm/FusedBatchNormV3) shape:[64], type:FLOAT32 RO 256 bytes\n",
            "  T#26(MobilenetV3large/expanded_conv_1/depthwise/BatchNorm/FusedBatchNormV3) shape:[64], type:FLOAT32 RO 256 bytes\n",
            "  T#27(MobilenetV3large/expanded_conv_2/expand/BatchNorm/FusedBatchNormV3) shape:[72], type:FLOAT32 RO 288 bytes\n",
            "  T#28(MobilenetV3large/expanded_conv_2/depthwise/BatchNorm/FusedBatchNormV3) shape:[72], type:FLOAT32 RO 288 bytes\n",
            "  T#29(MobilenetV3large/expanded_conv_3/expand/BatchNorm/FusedBatchNormV3) shape:[72], type:FLOAT32 RO 288 bytes\n",
            "  T#30(MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3) shape:[72], type:FLOAT32 RO 288 bytes\n",
            "  T#31(MobilenetV3large/expanded_conv_4/expand/BatchNorm/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes\n",
            "  T#32(MobilenetV3large/expanded_conv_4/depthwise/BatchNorm/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes\n",
            "  T#33(MobilenetV3large/expanded_conv_5/expand/BatchNorm/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes\n",
            "  T#34(MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3) shape:[120], type:FLOAT32 RO 480 bytes\n",
            "  T#35(MobilenetV3large/expanded_conv_6/depthwise/BatchNorm/FusedBatchNormV3) shape:[240], type:FLOAT32 RO 960 bytes\n",
            "  T#36(MobilenetV3large/expanded_conv_7/depthwise/BatchNorm/FusedBatchNormV3) shape:[200], type:FLOAT32 RO 800 bytes\n",
            "  T#37(MobilenetV3large/expanded_conv_8/depthwise/BatchNorm/FusedBatchNormV3) shape:[184], type:FLOAT32 RO 736 bytes\n",
            "  T#38(MobilenetV3large/expanded_conv_9/depthwise/BatchNorm/FusedBatchNormV3) shape:[184], type:FLOAT32 RO 736 bytes\n",
            "  T#39(MobilenetV3large/expanded_conv_10/depthwise/BatchNorm/FusedBatchNormV3) shape:[480], type:FLOAT32 RO 1920 bytes\n",
            "  T#40(MobilenetV3large/expanded_conv_11/depthwise/BatchNorm/FusedBatchNormV3) shape:[672], type:FLOAT32 RO 2688 bytes\n",
            "  T#41(MobilenetV3large/expanded_conv_12/depthwise/BatchNorm/FusedBatchNormV3) shape:[672], type:FLOAT32 RO 2688 bytes\n",
            "  T#42(MobilenetV3large/expanded_conv_13/depthwise/BatchNorm/FusedBatchNormV3) shape:[960], type:FLOAT32 RO 3840 bytes\n",
            "  T#43(MobilenetV3large/expanded_conv_14/depthwise/BatchNorm/FusedBatchNormV3) shape:[960], type:FLOAT32 RO 3840 bytes\n",
            "  T#44(MobilenetV3large/Conv/Conv2D) shape:[16, 3, 3, 3], type:FLOAT32 RO 1728 bytes\n",
            "  T#45(MobilenetV3large/expanded_conv/project/Conv2D) shape:[16, 1, 1, 16], type:FLOAT32 RO 1024 bytes\n",
            "  T#46(MobilenetV3large/expanded_conv_1/expand/Conv2D) shape:[64, 1, 1, 16], type:FLOAT32 RO 4096 bytes\n",
            "  T#47(MobilenetV3large/expanded_conv_1/project/Conv2D) shape:[24, 1, 1, 64], type:FLOAT32 RO 6144 bytes\n",
            "  T#48(MobilenetV3large/expanded_conv_2/expand/Conv2D) shape:[72, 1, 1, 24], type:FLOAT32 RO 6912 bytes\n",
            "  T#49(MobilenetV3large/expanded_conv_2/project/Conv2D) shape:[24, 1, 1, 72], type:FLOAT32 RO 6912 bytes\n",
            "  T#50(MobilenetV3large/expanded_conv_3/expand/Conv2D) shape:[72, 1, 1, 24], type:FLOAT32 RO 6912 bytes\n",
            "  T#51(MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D) shape:[24, 1, 1, 72], type:FLOAT32 RO 6912 bytes\n",
            "  T#52(MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D) shape:[72, 1, 1, 24], type:FLOAT32 RO 6912 bytes\n",
            "  T#53(MobilenetV3large/expanded_conv_3/project/Conv2D) shape:[40, 1, 1, 72], type:FLOAT32 RO 11520 bytes\n",
            "  T#54(MobilenetV3large/expanded_conv_4/expand/Conv2D) shape:[120, 1, 1, 40], type:FLOAT32 RO 19200 bytes\n",
            "  T#55(MobilenetV3large/expanded_conv_4/squeeze_excite/Conv/Conv2D) shape:[32, 1, 1, 120], type:FLOAT32 RO 15360 bytes\n",
            "  T#56(MobilenetV3large/expanded_conv_4/squeeze_excite/Conv_1/Conv2D) shape:[120, 1, 1, 32], type:FLOAT32 RO 15360 bytes\n",
            "  T#57(MobilenetV3large/expanded_conv_4/project/Conv2D) shape:[40, 1, 1, 120], type:FLOAT32 RO 19200 bytes\n",
            "  T#58(MobilenetV3large/expanded_conv_5/expand/Conv2D) shape:[120, 1, 1, 40], type:FLOAT32 RO 19200 bytes\n",
            "  T#59(MobilenetV3large/expanded_conv_5/squeeze_excite/Conv/Conv2D) shape:[32, 1, 1, 120], type:FLOAT32 RO 15360 bytes\n",
            "  T#60(MobilenetV3large/expanded_conv_5/squeeze_excite/Conv_1/Conv2D) shape:[120, 1, 1, 32], type:FLOAT32 RO 15360 bytes\n",
            "  T#61(MobilenetV3large/expanded_conv_5/project/Conv2D) shape:[40, 1, 1, 120], type:FLOAT32 RO 19200 bytes\n",
            "  T#62(MobilenetV3large/expanded_conv_6/expand/Conv2D) shape:[240, 1, 1, 40], type:FLOAT32 RO 38400 bytes\n",
            "  T#63(MobilenetV3large/expanded_conv_6/project/Conv2D) shape:[80, 1, 1, 240], type:FLOAT32 RO 76800 bytes\n",
            "  T#64(MobilenetV3large/expanded_conv_7/expand/Conv2D) shape:[200, 1, 1, 80], type:FLOAT32 RO 64000 bytes\n",
            "  T#65(MobilenetV3large/expanded_conv_7/project/Conv2D) shape:[80, 1, 1, 200], type:FLOAT32 RO 64000 bytes\n",
            "  T#66(MobilenetV3large/expanded_conv_8/expand/Conv2D) shape:[184, 1, 1, 80], type:FLOAT32 RO 58880 bytes\n",
            "  T#67(MobilenetV3large/expanded_conv_8/project/Conv2D) shape:[80, 1, 1, 184], type:FLOAT32 RO 58880 bytes\n",
            "  T#68(MobilenetV3large/expanded_conv_9/expand/Conv2D) shape:[184, 1, 1, 80], type:FLOAT32 RO 58880 bytes\n",
            "  T#69(MobilenetV3large/expanded_conv_9/project/Conv2D) shape:[80, 1, 1, 184], type:FLOAT32 RO 58880 bytes\n",
            "  T#70(MobilenetV3large/expanded_conv_10/expand/Conv2D) shape:[480, 1, 1, 80], type:FLOAT32 RO 153600 bytes\n",
            "  T#71(MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D) shape:[120, 1, 1, 480], type:FLOAT32 RO 230400 bytes\n",
            "  T#72(MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D) shape:[480, 1, 1, 120], type:FLOAT32 RO 230400 bytes\n",
            "  T#73(MobilenetV3large/expanded_conv_10/project/Conv2D) shape:[112, 1, 1, 480], type:FLOAT32 RO 215040 bytes\n",
            "  T#74(MobilenetV3large/expanded_conv_11/expand/Conv2D) shape:[672, 1, 1, 112], type:FLOAT32 RO 301056 bytes\n",
            "  T#75(MobilenetV3large/expanded_conv_11/squeeze_excite/Conv/Conv2D) shape:[168, 1, 1, 672], type:FLOAT32 RO 451584 bytes\n",
            "  T#76(MobilenetV3large/expanded_conv_11/squeeze_excite/Conv_1/Conv2D) shape:[672, 1, 1, 168], type:FLOAT32 RO 451584 bytes\n",
            "  T#77(MobilenetV3large/expanded_conv_11/project/Conv2D) shape:[112, 1, 1, 672], type:FLOAT32 RO 301056 bytes\n",
            "  T#78(MobilenetV3large/expanded_conv_12/expand/Conv2D) shape:[672, 1, 1, 112], type:FLOAT32 RO 301056 bytes\n",
            "  T#79(MobilenetV3large/expanded_conv_12/squeeze_excite/Conv/Conv2D) shape:[168, 1, 1, 672], type:FLOAT32 RO 451584 bytes\n",
            "  T#80(MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D) shape:[672, 1, 1, 168], type:FLOAT32 RO 451584 bytes\n",
            "  T#81(MobilenetV3large/expanded_conv_12/project/Conv2D) shape:[160, 1, 1, 672], type:FLOAT32 RO 430080 bytes\n",
            "  T#82(MobilenetV3large/expanded_conv_13/expand/Conv2D) shape:[960, 1, 1, 160], type:FLOAT32 RO 614400 bytes\n",
            "  T#83(MobilenetV3large/expanded_conv_13/squeeze_excite/Conv/Conv2D) shape:[240, 1, 1, 960], type:FLOAT32 RO 921600 bytes\n",
            "  T#84(MobilenetV3large/expanded_conv_13/squeeze_excite/Conv_1/Conv2D) shape:[960, 1, 1, 240], type:FLOAT32 RO 921600 bytes\n",
            "  T#85(MobilenetV3large/expanded_conv_13/project/Conv2D) shape:[160, 1, 1, 960], type:FLOAT32 RO 614400 bytes\n",
            "  T#86(MobilenetV3large/expanded_conv_14/expand/Conv2D) shape:[960, 1, 1, 160], type:FLOAT32 RO 614400 bytes\n",
            "  T#87(MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D) shape:[240, 1, 1, 960], type:FLOAT32 RO 921600 bytes\n",
            "  T#88(MobilenetV3large/expanded_conv_14/squeeze_excite/Conv_1/Conv2D) shape:[960, 1, 1, 240], type:FLOAT32 RO 921600 bytes\n",
            "  T#89(MobilenetV3large/expanded_conv_14/project/Conv2D) shape:[160, 1, 1, 960], type:FLOAT32 RO 614400 bytes\n",
            "  T#90(MobilenetV3large/Conv_1/Conv2D) shape:[960, 1, 1, 160], type:FLOAT32 RO 614400 bytes\n",
            "  T#91(MobilenetV3large/Conv_2/Conv2D) shape:[1280, 1, 1, 960], type:FLOAT32 RO 4915200 bytes\n",
            "  T#92(MobilenetV3large/Logits/Conv2D) shape:[1000, 1, 1, 1280], type:FLOAT32 RO 5120000 bytes\n",
            "  T#93(MobilenetV3large/Conv/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/project/Conv2D;MobilenetV3large/Conv/Conv2D) shape:[16], type:FLOAT32 RO 64 bytes\n",
            "  T#94(MobilenetV3large/expanded_conv/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/depthwise/depthwise;MobilenetV3large/expanded_conv/project/Conv2D) shape:[1, 3, 3, 16], type:FLOAT32 RO 576 bytes\n",
            "  T#95(MobilenetV3large/expanded_conv/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/project/Conv2D) shape:[16], type:FLOAT32 RO 64 bytes\n",
            "  T#96(MobilenetV3large/expanded_conv_1/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_1/depthwise/depthwise) shape:[1, 3, 3, 64], type:FLOAT32 RO 2304 bytes\n",
            "  T#97(MobilenetV3large/expanded_conv_1/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_1/project/Conv2D) shape:[24], type:FLOAT32 RO 96 bytes\n",
            "  T#98(MobilenetV3large/expanded_conv_2/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_2/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D) shape:[1, 3, 3, 72], type:FLOAT32 RO 2592 bytes\n",
            "  T#99(MobilenetV3large/expanded_conv_2/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_2/project/Conv2D) shape:[24], type:FLOAT32 RO 96 bytes\n",
            "  T#100(MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D) shape:[1, 5, 5, 72], type:FLOAT32 RO 7200 bytes\n",
            "  T#101(MobilenetV3large/expanded_conv_3/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D;MobilenetV3large/expanded_conv_3/project/Conv2D) shape:[40], type:FLOAT32 RO 160 bytes\n",
            "  T#102(MobilenetV3large/expanded_conv_4/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_4/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D) shape:[1, 5, 5, 120], type:FLOAT32 RO 12000 bytes\n",
            "  T#103(MobilenetV3large/expanded_conv_4/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D;MobilenetV3large/expanded_conv_4/project/Conv2D) shape:[40], type:FLOAT32 RO 160 bytes\n",
            "  T#104(MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D) shape:[1, 5, 5, 120], type:FLOAT32 RO 12000 bytes\n",
            "  T#105(MobilenetV3large/expanded_conv_5/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D) shape:[40], type:FLOAT32 RO 160 bytes\n",
            "  T#106(MobilenetV3large/expanded_conv_6/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_6/expand/Conv2D) shape:[240], type:FLOAT32 RO 960 bytes\n",
            "  T#107(MobilenetV3large/expanded_conv_6/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_6/depthwise/depthwise;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D) shape:[1, 3, 3, 240], type:FLOAT32 RO 8640 bytes\n",
            "  T#108(MobilenetV3large/expanded_conv_6/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_6/project/Conv2D) shape:[80], type:FLOAT32 RO 320 bytes\n",
            "  T#109(MobilenetV3large/expanded_conv_7/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_7/depthwise/depthwise;MobilenetV3large/expanded_conv_7/expand/Conv2D) shape:[200], type:FLOAT32 RO 800 bytes\n",
            "  T#110(MobilenetV3large/expanded_conv_7/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_7/depthwise/depthwise) shape:[1, 3, 3, 200], type:FLOAT32 RO 7200 bytes\n",
            "  T#111(MobilenetV3large/expanded_conv_7/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_7/project/Conv2D) shape:[80], type:FLOAT32 RO 320 bytes\n",
            "  T#112(MobilenetV3large/expanded_conv_8/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise;MobilenetV3large/expanded_conv_8/expand/Conv2D) shape:[184], type:FLOAT32 RO 736 bytes\n",
            "  T#113(MobilenetV3large/expanded_conv_8/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_8/depthwise/depthwise;MobilenetV3large/expanded_conv_9/depthwise/depthwise) shape:[1, 3, 3, 184], type:FLOAT32 RO 6624 bytes\n",
            "  T#114(MobilenetV3large/expanded_conv_8/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_8/project/Conv2D) shape:[80], type:FLOAT32 RO 320 bytes\n",
            "  T#115(MobilenetV3large/expanded_conv_9/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise;MobilenetV3large/expanded_conv_9/expand/Conv2D) shape:[184], type:FLOAT32 RO 736 bytes\n",
            "  T#116(MobilenetV3large/expanded_conv_9/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise) shape:[1, 3, 3, 184], type:FLOAT32 RO 6624 bytes\n",
            "  T#117(MobilenetV3large/expanded_conv_9/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D) shape:[80], type:FLOAT32 RO 320 bytes\n",
            "  T#118(MobilenetV3large/expanded_conv_10/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_10/expand/Conv2D) shape:[480], type:FLOAT32 RO 1920 bytes\n",
            "  T#119(MobilenetV3large/expanded_conv_10/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_10/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D) shape:[1, 3, 3, 480], type:FLOAT32 RO 17280 bytes\n",
            "  T#120(MobilenetV3large/expanded_conv_10/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/project/Conv2D;MobilenetV3large/expanded_conv_10/project/Conv2D) shape:[112], type:FLOAT32 RO 448 bytes\n",
            "  T#121(MobilenetV3large/expanded_conv_11/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_11/expand/Conv2D) shape:[672], type:FLOAT32 RO 2688 bytes\n",
            "  T#122(MobilenetV3large/expanded_conv_11/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/depthwise/depthwise;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D) shape:[1, 3, 3, 672], type:FLOAT32 RO 24192 bytes\n",
            "  T#123(MobilenetV3large/expanded_conv_11/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/project/Conv2D) shape:[112], type:FLOAT32 RO 448 bytes\n",
            "  T#124(MobilenetV3large/expanded_conv_12/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_12/expand/Conv2D) shape:[672], type:FLOAT32 RO 2688 bytes\n",
            "  T#125(MobilenetV3large/expanded_conv_12/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/depthwise/depthwise;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D) shape:[1, 5, 5, 672], type:FLOAT32 RO 67200 bytes\n",
            "  T#126(MobilenetV3large/expanded_conv_12/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D;MobilenetV3large/expanded_conv_12/project/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes\n",
            "  T#127(MobilenetV3large/expanded_conv_13/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_13/expand/Conv2D) shape:[960], type:FLOAT32 RO 3840 bytes\n",
            "  T#128(MobilenetV3large/expanded_conv_13/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_13/depthwise/depthwise;MobilenetV3large/Conv_1/Conv2D) shape:[1, 5, 5, 960], type:FLOAT32 RO 96000 bytes\n",
            "  T#129(MobilenetV3large/expanded_conv_13/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D;MobilenetV3large/expanded_conv_13/project/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes\n",
            "  T#130(MobilenetV3large/expanded_conv_14/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_14/expand/Conv2D) shape:[960], type:FLOAT32 RO 3840 bytes\n",
            "  T#131(MobilenetV3large/expanded_conv_14/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/depthwise/depthwise;MobilenetV3large/Conv_1/Conv2D) shape:[1, 5, 5, 960], type:FLOAT32 RO 96000 bytes\n",
            "  T#132(MobilenetV3large/expanded_conv_14/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D) shape:[160], type:FLOAT32 RO 640 bytes\n",
            "  T#133(MobilenetV3large/Conv_1/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D) shape:[960], type:FLOAT32 RO 3840 bytes\n",
            "  T#134(MobilenetV3large/Conv_2/BiasAdd;MobilenetV3large/Conv_2/Conv2D;Conv_2/bias) shape:[1280], type:FLOAT32 RO 5120 bytes\n",
            "  T#135(MobilenetV3large/Logits/BiasAdd;MobilenetV3large/Logits/Conv2D;Logits/bias) shape:[1000], type:FLOAT32 RO 4000 bytes\n",
            "  T#136(MobilenetV3large/rescaling/mul) shape_signature:[-1, -1, -1, 3], type:FLOAT32\n",
            "  T#137(MobilenetV3large/rescaling/add) shape_signature:[-1, -1, -1, 3], type:FLOAT32\n",
            "  T#138(MobilenetV3large/Conv/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/project/Conv2D;MobilenetV3large/Conv/Conv2D1) shape_signature:[-1, -1, -1, 16], type:FLOAT32\n",
            "  T#139(MobilenetV3large/multiply/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu/Relu6;MobilenetV3large/tf.__operators__.add/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply/Mul) shape_signature:[-1, -1, -1, 16], type:FLOAT32\n",
            "  T#140(MobilenetV3large/re_lu_1/Relu;MobilenetV3large/expanded_conv/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/depthwise/depthwise;MobilenetV3large/expanded_conv/project/Conv2D) shape_signature:[-1, -1, -1, 16], type:FLOAT32\n",
            "  T#141(MobilenetV3large/expanded_conv/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv/project/Conv2D1) shape_signature:[-1, -1, -1, 16], type:FLOAT32\n",
            "  T#142(MobilenetV3large/expanded_conv/Add/add) shape_signature:[-1, -1, -1, 16], type:FLOAT32\n",
            "  T#143(MobilenetV3large/re_lu_2/Relu;MobilenetV3large/expanded_conv_1/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_1/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_1/depthwise/depthwise;MobilenetV3large/expanded_conv_1/expand/Conv2D) shape_signature:[-1, -1, -1, 64], type:FLOAT32\n",
            "  T#144(MobilenetV3large/expanded_conv_1/depthwise/pad/Pad) shape_signature:[-1, -1, -1, 64], type:FLOAT32\n",
            "  T#145(MobilenetV3large/re_lu_3/Relu;MobilenetV3large/expanded_conv_1/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_1/depthwise/depthwise) shape_signature:[-1, -1, -1, 64], type:FLOAT32\n",
            "  T#146(MobilenetV3large/expanded_conv_1/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_1/project/Conv2D1) shape_signature:[-1, -1, -1, 24], type:FLOAT32\n",
            "  T#147(MobilenetV3large/re_lu_4/Relu;MobilenetV3large/expanded_conv_2/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_2/expand/Conv2D) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
            "  T#148(MobilenetV3large/re_lu_5/Relu;MobilenetV3large/expanded_conv_2/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_2/depthwise/depthwise) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
            "  T#149(MobilenetV3large/expanded_conv_2/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_2/project/Conv2D1) shape_signature:[-1, -1, -1, 24], type:FLOAT32\n",
            "  T#150(MobilenetV3large/expanded_conv_2/Add/add) shape_signature:[-1, -1, -1, 24], type:FLOAT32\n",
            "  T#151(MobilenetV3large/re_lu_6/Relu;MobilenetV3large/expanded_conv_3/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_3/expand/Conv2D) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
            "  T#152(MobilenetV3large/expanded_conv_3/depthwise/pad/Pad) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
            "  T#153(MobilenetV3large/re_lu_7/Relu;MobilenetV3large/expanded_conv_3/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_3/depthwise/depthwise;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
            "  T#154(MobilenetV3large/expanded_conv_3/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 72], type:FLOAT32\n",
            "  T#155(MobilenetV3large/expanded_conv_3/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv/Conv2D;expanded_conv_3/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 24], type:FLOAT32\n",
            "  T#156(MobilenetV3large/re_lu_8/Relu6;MobilenetV3large/tf.__operators__.add_1/AddV2;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_3/squeeze_excite/Conv_1/Conv2D;expanded_conv_3/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 72], type:FLOAT32\n",
            "  T#157(MobilenetV3large/tf.math.multiply_1/Mul) shape_signature:[-1, 1, 1, 72], type:FLOAT32\n",
            "  T#158(MobilenetV3large/expanded_conv_3/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 72], type:FLOAT32\n",
            "  T#159(MobilenetV3large/expanded_conv_3/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D;MobilenetV3large/expanded_conv_3/project/Conv2D1) shape_signature:[-1, -1, -1, 40], type:FLOAT32\n",
            "  T#160(MobilenetV3large/re_lu_9/Relu;MobilenetV3large/expanded_conv_4/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_4/expand/Conv2D) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
            "  T#161(MobilenetV3large/re_lu_10/Relu;MobilenetV3large/expanded_conv_4/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_4/depthwise/depthwise) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
            "  T#162(MobilenetV3large/expanded_conv_4/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
            "  T#163(MobilenetV3large/expanded_conv_4/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv/Conv2D;expanded_conv_4/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 32], type:FLOAT32\n",
            "  T#164(MobilenetV3large/re_lu_11/Relu6;MobilenetV3large/tf.__operators__.add_2/AddV2;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_4/squeeze_excite/Conv_1/Conv2D;expanded_conv_4/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
            "  T#165(MobilenetV3large/tf.math.multiply_2/Mul) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
            "  T#166(MobilenetV3large/expanded_conv_4/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
            "  T#167(MobilenetV3large/expanded_conv_4/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D;MobilenetV3large/expanded_conv_4/project/Conv2D1) shape_signature:[-1, -1, -1, 40], type:FLOAT32\n",
            "  T#168(MobilenetV3large/expanded_conv_4/Add/add) shape_signature:[-1, -1, -1, 40], type:FLOAT32\n",
            "  T#169(MobilenetV3large/re_lu_12/Relu;MobilenetV3large/expanded_conv_5/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_5/expand/Conv2D) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
            "  T#170(MobilenetV3large/re_lu_13/Relu;MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
            "  T#171(MobilenetV3large/expanded_conv_5/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
            "  T#172(MobilenetV3large/expanded_conv_5/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv/Conv2D;expanded_conv_5/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 32], type:FLOAT32\n",
            "  T#173(MobilenetV3large/re_lu_14/Relu6;MobilenetV3large/tf.__operators__.add_3/AddV2;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_5/squeeze_excite/Conv_1/Conv2D;expanded_conv_5/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
            "  T#174(MobilenetV3large/tf.math.multiply_3/Mul) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
            "  T#175(MobilenetV3large/expanded_conv_5/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 120], type:FLOAT32\n",
            "  T#176(MobilenetV3large/expanded_conv_5/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/project/Conv2D1) shape_signature:[-1, -1, -1, 40], type:FLOAT32\n",
            "  T#177(MobilenetV3large/expanded_conv_5/Add/add) shape_signature:[-1, -1, -1, 40], type:FLOAT32\n",
            "  T#178(MobilenetV3large/expanded_conv_6/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_6/expand/Conv2D1) shape_signature:[-1, -1, -1, 240], type:FLOAT32\n",
            "  T#179(MobilenetV3large/multiply_1/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_15/Relu6;MobilenetV3large/tf.__operators__.add_4/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_4/Mul) shape_signature:[-1, -1, -1, 240], type:FLOAT32\n",
            "  T#180(MobilenetV3large/expanded_conv_6/depthwise/pad/Pad) shape_signature:[-1, -1, -1, 240], type:FLOAT32\n",
            "  T#181(MobilenetV3large/expanded_conv_6/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_6/depthwise/depthwise;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D1) shape_signature:[-1, -1, -1, 240], type:FLOAT32\n",
            "  T#182(MobilenetV3large/multiply_2/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_16/Relu6;MobilenetV3large/tf.__operators__.add_5/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_5/Mul) shape_signature:[-1, -1, -1, 240], type:FLOAT32\n",
            "  T#183(MobilenetV3large/expanded_conv_6/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_6/project/Conv2D1) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
            "  T#184(MobilenetV3large/expanded_conv_7/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_7/depthwise/depthwise;MobilenetV3large/expanded_conv_7/expand/Conv2D1) shape_signature:[-1, -1, -1, 200], type:FLOAT32\n",
            "  T#185(MobilenetV3large/multiply_3/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_17/Relu6;MobilenetV3large/tf.__operators__.add_6/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_6/Mul) shape_signature:[-1, -1, -1, 200], type:FLOAT32\n",
            "  T#186(MobilenetV3large/expanded_conv_7/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_7/depthwise/depthwise1) shape_signature:[-1, -1, -1, 200], type:FLOAT32\n",
            "  T#187(MobilenetV3large/multiply_4/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_18/Relu6;MobilenetV3large/tf.__operators__.add_7/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_7/Mul) shape_signature:[-1, -1, -1, 200], type:FLOAT32\n",
            "  T#188(MobilenetV3large/expanded_conv_7/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_7/project/Conv2D1) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
            "  T#189(MobilenetV3large/expanded_conv_7/Add/add) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
            "  T#190(MobilenetV3large/expanded_conv_8/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise;MobilenetV3large/expanded_conv_8/expand/Conv2D1) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
            "  T#191(MobilenetV3large/multiply_5/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_19/Relu6;MobilenetV3large/tf.__operators__.add_8/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_8/Mul) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
            "  T#192(MobilenetV3large/expanded_conv_8/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise;MobilenetV3large/expanded_conv_8/depthwise/depthwise) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
            "  T#193(MobilenetV3large/multiply_6/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_20/Relu6;MobilenetV3large/tf.__operators__.add_9/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_9/Mul) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
            "  T#194(MobilenetV3large/expanded_conv_8/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D;MobilenetV3large/expanded_conv_8/project/Conv2D1) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
            "  T#195(MobilenetV3large/expanded_conv_8/Add/add) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
            "  T#196(MobilenetV3large/expanded_conv_9/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise;MobilenetV3large/expanded_conv_9/expand/Conv2D1) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
            "  T#197(MobilenetV3large/multiply_7/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_21/Relu6;MobilenetV3large/tf.__operators__.add_10/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_10/Mul) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
            "  T#198(MobilenetV3large/expanded_conv_9/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/depthwise/depthwise1) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
            "  T#199(MobilenetV3large/multiply_8/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_22/Relu6;MobilenetV3large/tf.__operators__.add_11/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_11/Mul) shape_signature:[-1, -1, -1, 184], type:FLOAT32\n",
            "  T#200(MobilenetV3large/expanded_conv_9/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_9/project/Conv2D1) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
            "  T#201(MobilenetV3large/expanded_conv_9/Add/add) shape_signature:[-1, -1, -1, 80], type:FLOAT32\n",
            "  T#202(MobilenetV3large/expanded_conv_10/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_10/expand/Conv2D1) shape_signature:[-1, -1, -1, 480], type:FLOAT32\n",
            "  T#203(MobilenetV3large/multiply_9/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_23/Relu6;MobilenetV3large/tf.__operators__.add_12/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_12/Mul) shape_signature:[-1, -1, -1, 480], type:FLOAT32\n",
            "  T#204(MobilenetV3large/expanded_conv_10/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_10/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D1) shape_signature:[-1, -1, -1, 480], type:FLOAT32\n",
            "  T#205(MobilenetV3large/multiply_10/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_24/Relu6;MobilenetV3large/tf.__operators__.add_13/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_13/Mul) shape_signature:[-1, -1, -1, 480], type:FLOAT32\n",
            "  T#206(MobilenetV3large/expanded_conv_10/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 480], type:FLOAT32\n",
            "  T#207(MobilenetV3large/expanded_conv_10/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_5/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_5/depthwise/depthwise;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv/Conv2D;expanded_conv_10/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 120], type:FLOAT32\n",
            "  T#208(MobilenetV3large/re_lu_25/Relu6;MobilenetV3large/tf.__operators__.add_14/AddV2;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_10/squeeze_excite/Conv_1/Conv2D;expanded_conv_10/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 480], type:FLOAT32\n",
            "  T#209(MobilenetV3large/tf.math.multiply_14/Mul) shape_signature:[-1, 1, 1, 480], type:FLOAT32\n",
            "  T#210(MobilenetV3large/expanded_conv_10/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 480], type:FLOAT32\n",
            "  T#211(MobilenetV3large/expanded_conv_10/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/project/Conv2D;MobilenetV3large/expanded_conv_10/project/Conv2D1) shape_signature:[-1, -1, -1, 112], type:FLOAT32\n",
            "  T#212(MobilenetV3large/expanded_conv_11/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_11/expand/Conv2D1) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#213(MobilenetV3large/multiply_11/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_26/Relu6;MobilenetV3large/tf.__operators__.add_15/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_15/Mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#214(MobilenetV3large/expanded_conv_11/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/depthwise/depthwise;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D1) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#215(MobilenetV3large/multiply_12/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_27/Relu6;MobilenetV3large/tf.__operators__.add_16/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_16/Mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#216(MobilenetV3large/expanded_conv_11/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
            "  T#217(MobilenetV3large/expanded_conv_11/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv/Conv2D;expanded_conv_11/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 168], type:FLOAT32\n",
            "  T#218(MobilenetV3large/re_lu_28/Relu6;MobilenetV3large/tf.__operators__.add_17/AddV2;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_11/squeeze_excite/Conv_1/Conv2D;expanded_conv_11/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
            "  T#219(MobilenetV3large/tf.math.multiply_17/Mul) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
            "  T#220(MobilenetV3large/expanded_conv_11/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#221(MobilenetV3large/expanded_conv_11/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_11/project/Conv2D1) shape_signature:[-1, -1, -1, 112], type:FLOAT32\n",
            "  T#222(MobilenetV3large/expanded_conv_11/Add/add) shape_signature:[-1, -1, -1, 112], type:FLOAT32\n",
            "  T#223(MobilenetV3large/expanded_conv_12/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;MobilenetV3large/expanded_conv_12/expand/Conv2D1) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#224(MobilenetV3large/multiply_13/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_29/Relu6;MobilenetV3large/tf.__operators__.add_18/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_18/Mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#225(MobilenetV3large/expanded_conv_12/depthwise/pad/Pad) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#226(MobilenetV3large/expanded_conv_12/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_12/depthwise/depthwise;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D1) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#227(MobilenetV3large/multiply_14/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_30/Relu6;MobilenetV3large/tf.__operators__.add_19/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_19/Mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#228(MobilenetV3large/expanded_conv_12/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
            "  T#229(MobilenetV3large/expanded_conv_12/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv/Conv2D;expanded_conv_12/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 168], type:FLOAT32\n",
            "  T#230(MobilenetV3large/re_lu_31/Relu6;MobilenetV3large/tf.__operators__.add_20/AddV2;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/expanded_conv_12/squeeze_excite/Conv_1/Conv2D;expanded_conv_12/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
            "  T#231(MobilenetV3large/tf.math.multiply_20/Mul) shape_signature:[-1, 1, 1, 672], type:FLOAT32\n",
            "  T#232(MobilenetV3large/expanded_conv_12/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 672], type:FLOAT32\n",
            "  T#233(MobilenetV3large/expanded_conv_12/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D;MobilenetV3large/expanded_conv_12/project/Conv2D1) shape_signature:[-1, -1, -1, 160], type:FLOAT32\n",
            "  T#234(MobilenetV3large/expanded_conv_13/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_13/expand/Conv2D1) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#235(MobilenetV3large/multiply_15/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_32/Relu6;MobilenetV3large/tf.__operators__.add_21/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_21/Mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#236(MobilenetV3large/expanded_conv_13/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/depthwise/depthwise;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_13/depthwise/depthwise) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#237(MobilenetV3large/multiply_16/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_33/Relu6;MobilenetV3large/tf.__operators__.add_22/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_22/Mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#238(MobilenetV3large/expanded_conv_13/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
            "  T#239(MobilenetV3large/expanded_conv_13/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_6/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_6/depthwise/depthwise;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv/Conv2D;expanded_conv_13/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 240], type:FLOAT32\n",
            "  T#240(MobilenetV3large/re_lu_34/Relu6;MobilenetV3large/tf.__operators__.add_23/AddV2;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_13/squeeze_excite/Conv_1/Conv2D;expanded_conv_13/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
            "  T#241(MobilenetV3large/tf.math.multiply_23/Mul) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
            "  T#242(MobilenetV3large/expanded_conv_13/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#243(MobilenetV3large/expanded_conv_13/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D;MobilenetV3large/expanded_conv_13/project/Conv2D1) shape_signature:[-1, -1, -1, 160], type:FLOAT32\n",
            "  T#244(MobilenetV3large/expanded_conv_13/Add/add) shape_signature:[-1, -1, -1, 160], type:FLOAT32\n",
            "  T#245(MobilenetV3large/expanded_conv_14/expand/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_14/expand/Conv2D1) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#246(MobilenetV3large/multiply_17/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_35/Relu6;MobilenetV3large/tf.__operators__.add_24/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_24/Mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#247(MobilenetV3large/expanded_conv_14/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/depthwise/depthwise;MobilenetV3large/Conv_1/Conv2D1) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#248(MobilenetV3large/multiply_18/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_36/Relu6;MobilenetV3large/tf.__operators__.add_25/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_25/Mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#249(MobilenetV3large/expanded_conv_14/squeeze_excite/AvgPool/Mean) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
            "  T#250(MobilenetV3large/expanded_conv_14/squeeze_excite/Relu/Relu;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/BiasAdd;MobilenetV3large/expanded_conv_6/depthwise/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_6/depthwise/depthwise;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv/Conv2D;expanded_conv_14/squeeze_excite/Conv/bias) shape_signature:[-1, 1, 1, 240], type:FLOAT32\n",
            "  T#251(MobilenetV3large/re_lu_37/Relu6;MobilenetV3large/tf.__operators__.add_26/AddV2;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv_1/BiasAdd;MobilenetV3large/Conv_1/Conv2D;MobilenetV3large/expanded_conv_14/squeeze_excite/Conv_1/Conv2D;expanded_conv_14/squeeze_excite/Conv_1/bias;MobilenetV3large/tf.__operators__.add/y1) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
            "  T#252(MobilenetV3large/tf.math.multiply_26/Mul) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
            "  T#253(MobilenetV3large/expanded_conv_14/squeeze_excite/Mul/mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#254(MobilenetV3large/expanded_conv_14/project/BatchNorm/FusedBatchNormV3;MobilenetV3large/expanded_conv_14/project/Conv2D1) shape_signature:[-1, -1, -1, 160], type:FLOAT32\n",
            "  T#255(MobilenetV3large/expanded_conv_14/Add/add) shape_signature:[-1, -1, -1, 160], type:FLOAT32\n",
            "  T#256(MobilenetV3large/Conv_1/BatchNorm/FusedBatchNormV3;MobilenetV3large/Conv_1/Conv2D1) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#257(MobilenetV3large/multiply_19/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_38/Relu6;MobilenetV3large/tf.__operators__.add_27/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_27/Mul) shape_signature:[-1, -1, -1, 960], type:FLOAT32\n",
            "  T#258(MobilenetV3large/global_average_pooling2d/Mean) shape_signature:[-1, 1, 1, 960], type:FLOAT32\n",
            "  T#259(MobilenetV3large/Conv_2/BiasAdd;MobilenetV3large/Conv_2/Conv2D;Conv_2/bias1) shape_signature:[-1, 1, 1, 1280], type:FLOAT32\n",
            "  T#260(MobilenetV3large/multiply_20/mul;MobilenetV3large/tf.__operators__.add/y;MobilenetV3large/re_lu_39/Relu6;MobilenetV3large/tf.__operators__.add_28/AddV2;MobilenetV3large/tf.math.multiply/Mul/y;MobilenetV3large/tf.math.multiply_28/Mul) shape_signature:[-1, 1, 1, 1280], type:FLOAT32\n",
            "  T#261(MobilenetV3large/Logits/BiasAdd;MobilenetV3large/Logits/Conv2D;Logits/bias1) shape_signature:[-1, 1, 1, 1000], type:FLOAT32\n",
            "  T#262(MobilenetV3large/flatten/Reshape) shape_signature:[-1, 1000], type:FLOAT32\n",
            "  T#263(StatefulPartitionedCall:0) shape_signature:[-1, 1000], type:FLOAT32\n",
            "\n",
            "---------------------------------------------------------------\n",
            "Your TFLite model has ‘1’ signature_def(s).\n",
            "\n",
            "Signature#0 key: 'serving_default'\n",
            "- Subgraph: Subgraph#0\n",
            "- Inputs: \n",
            "    'input_1' : T#0\n",
            "- Outputs: \n",
            "    'Predictions' : T#263\n",
            "\n",
            "---------------------------------------------------------------\n",
            "              Model size:   21944892 bytes\n",
            "    Non-data buffer size:      61456 bytes (00.28 %)\n",
            "  Total data buffer size:   21883436 bytes (99.72 %)\n",
            "    (Zero value buffers):          0 bytes (00.00 %)\n",
            "\n",
            "* Buffers of TFLite model are mostly used for constant tensors.\n",
            "  And zero value buffers are buffers filled with zeros.\n",
            "  Non-data buffers area are used to store operators, subgraphs and etc.\n",
            "  You can find more details from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema.fbs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcirHeTIf8fE",
        "outputId": "6b162dcb-94da-48dc-b79f-d9b79e303682"
      },
      "id": "xcirHeTIf8fE",
      "execution_count": 560,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model_file = pathlib.Path('/content/model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_JTLUPL-w3H",
        "outputId": "2523caf2-7d49-4fae-d152-5eece091a98d"
      },
      "id": "j_JTLUPL-w3H",
      "execution_count": 561,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "345808"
            ]
          },
          "metadata": {},
          "execution_count": 561
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(tflite_model_files, 'rb') as fid:\n",
        "    tflite_model = fid.read()\n",
        "    \n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ],
      "metadata": {
        "id": "v-wM4W7-m4uK"
      },
      "id": "v-wM4W7-m4uK",
      "execution_count": 563,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(tflite_model_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VCcPLCLVm5lj",
        "outputId": "35119a9e-3a65-455c-9ccc-9260dd97f4b2"
      },
      "id": "VCcPLCLVm5lj",
      "execution_count": 564,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f830f37b-9158-4d99-bf02-3b19fde42f9b\", \"model.tflite\", 345808)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "Model Stunting.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}